{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Ruta de logs (usa fecha para evitar sobrescribir)\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow --user\n",
    "#!pip install keras --user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yporq\\AppData\\Local\\Temp\\ipykernel_28740\\4213989973.py:2: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)  # o más directamente:\n",
    "tf.compat.v1.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yporq\\AppData\\Local\\Temp\\ipykernel_28740\\3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Flatten name=flatten_1, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*28*28 + 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.5118 - loss: 1.7313 - val_accuracy: 0.8684 - val_loss: 0.5889\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.8623 - loss: 0.5631 - val_accuracy: 0.8983 - val_loss: 0.3892\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8880 - loss: 0.4136 - val_accuracy: 0.9082 - val_loss: 0.3319\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8993 - loss: 0.3597 - val_accuracy: 0.9154 - val_loss: 0.3021\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9085 - loss: 0.3259 - val_accuracy: 0.9194 - val_loss: 0.2847\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.9144 - loss: 0.3032 - val_accuracy: 0.9233 - val_loss: 0.2655\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9187 - loss: 0.2876 - val_accuracy: 0.9260 - val_loss: 0.2522\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9235 - loss: 0.2702 - val_accuracy: 0.9288 - val_loss: 0.2424\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9278 - loss: 0.2544 - val_accuracy: 0.9319 - val_loss: 0.2344\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9292 - loss: 0.2482 - val_accuracy: 0.9365 - val_loss: 0.2229\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9338 - loss: 0.2360 - val_accuracy: 0.9380 - val_loss: 0.2152\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.9374 - loss: 0.2223 - val_accuracy: 0.9406 - val_loss: 0.2089\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 37ms/step - accuracy: 0.9401 - loss: 0.2157 - val_accuracy: 0.9425 - val_loss: 0.2008\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 49ms/step - accuracy: 0.9399 - loss: 0.2118 - val_accuracy: 0.9445 - val_loss: 0.1965\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9428 - loss: 0.2016 - val_accuracy: 0.9472 - val_loss: 0.1891\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - accuracy: 0.9448 - loss: 0.1966 - val_accuracy: 0.9498 - val_loss: 0.1837\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 59ms/step - accuracy: 0.9450 - loss: 0.1920 - val_accuracy: 0.9486 - val_loss: 0.1805\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 72ms/step - accuracy: 0.9478 - loss: 0.1824 - val_accuracy: 0.9509 - val_loss: 0.1761\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.9487 - loss: 0.1773 - val_accuracy: 0.9523 - val_loss: 0.1713\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - accuracy: 0.9489 - loss: 0.1773 - val_accuracy: 0.9532 - val_loss: 0.1676\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - accuracy: 0.9520 - loss: 0.1650 - val_accuracy: 0.9546 - val_loss: 0.1632\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - accuracy: 0.9536 - loss: 0.1614 - val_accuracy: 0.9557 - val_loss: 0.1603\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - accuracy: 0.9546 - loss: 0.1583 - val_accuracy: 0.9565 - val_loss: 0.1562\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 45ms/step - accuracy: 0.9548 - loss: 0.1567 - val_accuracy: 0.9572 - val_loss: 0.1538\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9561 - loss: 0.1509 - val_accuracy: 0.9580 - val_loss: 0.1503\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9577 - loss: 0.1461 - val_accuracy: 0.9586 - val_loss: 0.1485\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - accuracy: 0.9588 - loss: 0.1429 - val_accuracy: 0.9589 - val_loss: 0.1450\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - accuracy: 0.9602 - loss: 0.1372 - val_accuracy: 0.9604 - val_loss: 0.1432\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9600 - loss: 0.1396 - val_accuracy: 0.9611 - val_loss: 0.1401\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9631 - loss: 0.1330 - val_accuracy: 0.9613 - val_loss: 0.1388\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.9627 - loss: 0.1299 - val_accuracy: 0.9625 - val_loss: 0.1354\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9648 - loss: 0.1258 - val_accuracy: 0.9635 - val_loss: 0.1327\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9646 - loss: 0.1234 - val_accuracy: 0.9637 - val_loss: 0.1312\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9674 - loss: 0.1159 - val_accuracy: 0.9640 - val_loss: 0.1288\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9661 - loss: 0.1214 - val_accuracy: 0.9645 - val_loss: 0.1277\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9688 - loss: 0.1125 - val_accuracy: 0.9647 - val_loss: 0.1256\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9686 - loss: 0.1125 - val_accuracy: 0.9658 - val_loss: 0.1241\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9694 - loss: 0.1089 - val_accuracy: 0.9657 - val_loss: 0.1231\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9698 - loss: 0.1074 - val_accuracy: 0.9666 - val_loss: 0.1213\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9704 - loss: 0.1033 - val_accuracy: 0.9669 - val_loss: 0.1201\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9724 - loss: 0.0992 - val_accuracy: 0.9678 - val_loss: 0.1177\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9719 - loss: 0.1023 - val_accuracy: 0.9683 - val_loss: 0.1161\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9732 - loss: 0.0988 - val_accuracy: 0.9682 - val_loss: 0.1154\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9731 - loss: 0.0972 - val_accuracy: 0.9685 - val_loss: 0.1135\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9737 - loss: 0.0950 - val_accuracy: 0.9693 - val_loss: 0.1125\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9747 - loss: 0.0915 - val_accuracy: 0.9683 - val_loss: 0.1121\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9759 - loss: 0.0884 - val_accuracy: 0.9703 - val_loss: 0.1102\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9757 - loss: 0.0897 - val_accuracy: 0.9698 - val_loss: 0.1094\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9751 - loss: 0.0881 - val_accuracy: 0.9693 - val_loss: 0.1083\n",
      "Epoch 50/50\n",
      "\u001b[1m389/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9763 - loss: 0.0880"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val), # validation_split = 0.1\n",
    "    callbacks=[tensorboard_callback] #aquí guardamos los datos de entrenamiento(loss, accuracy, val_loss... en logs/fit/)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.0828 - val_accuracy: 0.9700 - val_loss: 0.1065\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9769 - loss: 0.0825 - val_accuracy: 0.9703 - val_loss: 0.1060\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9782 - loss: 0.0803 - val_accuracy: 0.9707 - val_loss: 0.1047\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9795 - loss: 0.0746 - val_accuracy: 0.9715 - val_loss: 0.1002\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9793 - loss: 0.0749 - val_accuracy: 0.9711 - val_loss: 0.0987\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.0695 - val_accuracy: 0.9717 - val_loss: 0.0987\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.0687 - val_accuracy: 0.9730 - val_loss: 0.0968\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.0663 - val_accuracy: 0.9715 - val_loss: 0.0985\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.0617 - val_accuracy: 0.9733 - val_loss: 0.0939\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0606 - val_accuracy: 0.9737 - val_loss: 0.0923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b3c3c6b5d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 'auto', 'epochs': 50, 'steps': 391}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.6872599720954895,\n",
       "  0.8696200251579285,\n",
       "  0.8906999826431274,\n",
       "  0.9021000266075134,\n",
       "  0.909820020198822,\n",
       "  0.9157999753952026,\n",
       "  0.9209200143814087,\n",
       "  0.9245399832725525,\n",
       "  0.9281200170516968,\n",
       "  0.9313600063323975,\n",
       "  0.9339399933815002,\n",
       "  0.9366199970245361,\n",
       "  0.9395999908447266,\n",
       "  0.9413599967956543,\n",
       "  0.9434199929237366,\n",
       "  0.9454200267791748,\n",
       "  0.947160005569458,\n",
       "  0.9487000107765198,\n",
       "  0.9498599767684937,\n",
       "  0.9515399932861328,\n",
       "  0.9528800249099731,\n",
       "  0.9540200233459473,\n",
       "  0.9553200006484985,\n",
       "  0.9569000005722046,\n",
       "  0.9576600193977356,\n",
       "  0.9591599702835083,\n",
       "  0.959559977054596,\n",
       "  0.9613199830055237,\n",
       "  0.9625399708747864,\n",
       "  0.9630200266838074,\n",
       "  0.9643599987030029,\n",
       "  0.9650800228118896,\n",
       "  0.966480016708374,\n",
       "  0.9670600295066833,\n",
       "  0.9681000113487244,\n",
       "  0.9686800241470337,\n",
       "  0.9697399735450745,\n",
       "  0.9700199961662292,\n",
       "  0.9711800217628479,\n",
       "  0.9717599749565125,\n",
       "  0.972320020198822,\n",
       "  0.972760021686554,\n",
       "  0.9734600186347961,\n",
       "  0.9744799733161926,\n",
       "  0.9747800230979919,\n",
       "  0.9754599928855896,\n",
       "  0.9758599996566772,\n",
       "  0.9761000275611877,\n",
       "  0.9768000245094299,\n",
       "  0.9775199890136719],\n",
       " 'loss': [1.2834657430648804,\n",
       "  0.5124450325965881,\n",
       "  0.39521902799606323,\n",
       "  0.34666934609413147,\n",
       "  0.31750836968421936,\n",
       "  0.2958011031150818,\n",
       "  0.27900588512420654,\n",
       "  0.26507991552352905,\n",
       "  0.25291335582733154,\n",
       "  0.24189233779907227,\n",
       "  0.23200464248657227,\n",
       "  0.222923144698143,\n",
       "  0.2145502120256424,\n",
       "  0.20690228044986725,\n",
       "  0.19970495998859406,\n",
       "  0.1929681897163391,\n",
       "  0.18652747571468353,\n",
       "  0.18067340552806854,\n",
       "  0.17489424347877502,\n",
       "  0.16977417469024658,\n",
       "  0.1644749641418457,\n",
       "  0.1599094569683075,\n",
       "  0.15530234575271606,\n",
       "  0.1510043889284134,\n",
       "  0.14667196571826935,\n",
       "  0.1427895575761795,\n",
       "  0.13901081681251526,\n",
       "  0.13532112538814545,\n",
       "  0.13186636567115784,\n",
       "  0.12863264977931976,\n",
       "  0.12532581388950348,\n",
       "  0.12232533097267151,\n",
       "  0.11939577013254166,\n",
       "  0.11669562757015228,\n",
       "  0.1137651652097702,\n",
       "  0.11115433275699615,\n",
       "  0.1086902916431427,\n",
       "  0.1062961146235466,\n",
       "  0.10405721515417099,\n",
       "  0.10153509676456451,\n",
       "  0.0994952917098999,\n",
       "  0.09745070338249207,\n",
       "  0.09527333080768585,\n",
       "  0.09332779049873352,\n",
       "  0.09129121154546738,\n",
       "  0.08953031152486801,\n",
       "  0.08769015967845917,\n",
       "  0.0859295129776001,\n",
       "  0.08427786082029343,\n",
       "  0.08253870904445648],\n",
       " 'val_accuracy': [0.8655999898910522,\n",
       "  0.8974999785423279,\n",
       "  0.9092000126838684,\n",
       "  0.9161999821662903,\n",
       "  0.9211000204086304,\n",
       "  0.9251999855041504,\n",
       "  0.9297000169754028,\n",
       "  0.9337000250816345,\n",
       "  0.9368000030517578,\n",
       "  0.9380000233650208,\n",
       "  0.9409999847412109,\n",
       "  0.9416999816894531,\n",
       "  0.9438999891281128,\n",
       "  0.9453999996185303,\n",
       "  0.9480000138282776,\n",
       "  0.9505000114440918,\n",
       "  0.95169997215271,\n",
       "  0.9528999924659729,\n",
       "  0.9541000127792358,\n",
       "  0.9550999999046326,\n",
       "  0.9562000036239624,\n",
       "  0.9573000073432922,\n",
       "  0.9584000110626221,\n",
       "  0.9596999883651733,\n",
       "  0.9599000215530396,\n",
       "  0.9606999754905701,\n",
       "  0.9624999761581421,\n",
       "  0.9631999731063843,\n",
       "  0.9639000296592712,\n",
       "  0.9648000001907349,\n",
       "  0.9650999903678894,\n",
       "  0.9657999873161316,\n",
       "  0.9645000100135803,\n",
       "  0.96670001745224,\n",
       "  0.9663000106811523,\n",
       "  0.9661999940872192,\n",
       "  0.9682999849319458,\n",
       "  0.9674999713897705,\n",
       "  0.9682999849319458,\n",
       "  0.968500018119812,\n",
       "  0.9695000052452087,\n",
       "  0.9697999954223633,\n",
       "  0.9696000218391418,\n",
       "  0.9702000021934509,\n",
       "  0.97079998254776,\n",
       "  0.9714999794960022,\n",
       "  0.9711999893188477,\n",
       "  0.9715999960899353,\n",
       "  0.9724000096321106,\n",
       "  0.9729999899864197],\n",
       " 'val_loss': [0.5993039011955261,\n",
       "  0.3932127356529236,\n",
       "  0.332370400428772,\n",
       "  0.3014335334300995,\n",
       "  0.28046417236328125,\n",
       "  0.26564809679985046,\n",
       "  0.2516059875488281,\n",
       "  0.23942133784294128,\n",
       "  0.228723406791687,\n",
       "  0.2215261459350586,\n",
       "  0.21234512329101562,\n",
       "  0.20537415146827698,\n",
       "  0.20187975466251373,\n",
       "  0.19465143978595734,\n",
       "  0.1867169737815857,\n",
       "  0.1820165067911148,\n",
       "  0.17665129899978638,\n",
       "  0.17276319861412048,\n",
       "  0.16840647161006927,\n",
       "  0.16437433660030365,\n",
       "  0.1599218249320984,\n",
       "  0.1556171327829361,\n",
       "  0.15241821110248566,\n",
       "  0.14950121939182281,\n",
       "  0.14674390852451324,\n",
       "  0.1437484174966812,\n",
       "  0.14109814167022705,\n",
       "  0.13741284608840942,\n",
       "  0.13497287034988403,\n",
       "  0.13269536197185516,\n",
       "  0.13085989654064178,\n",
       "  0.12847217917442322,\n",
       "  0.12852704524993896,\n",
       "  0.12429693341255188,\n",
       "  0.123092420399189,\n",
       "  0.12270378321409225,\n",
       "  0.11985176056623459,\n",
       "  0.11870728433132172,\n",
       "  0.11633366346359253,\n",
       "  0.11553610861301422,\n",
       "  0.11368971318006516,\n",
       "  0.111483633518219,\n",
       "  0.11048195511102676,\n",
       "  0.10951639711856842,\n",
       "  0.10865259915590286,\n",
       "  0.10712690651416779,\n",
       "  0.10582633316516876,\n",
       "  0.1056218296289444,\n",
       "  0.10343911498785019,\n",
       "  0.10444143414497375]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.6872599720954895,\n",
       "  0.8696200251579285,\n",
       "  0.8906999826431274,\n",
       "  0.9021000266075134,\n",
       "  0.909820020198822,\n",
       "  0.9157999753952026,\n",
       "  0.9209200143814087,\n",
       "  0.9245399832725525,\n",
       "  0.9281200170516968,\n",
       "  0.9313600063323975,\n",
       "  0.9339399933815002,\n",
       "  0.9366199970245361,\n",
       "  0.9395999908447266,\n",
       "  0.9413599967956543,\n",
       "  0.9434199929237366,\n",
       "  0.9454200267791748,\n",
       "  0.947160005569458,\n",
       "  0.9487000107765198,\n",
       "  0.9498599767684937,\n",
       "  0.9515399932861328,\n",
       "  0.9528800249099731,\n",
       "  0.9540200233459473,\n",
       "  0.9553200006484985,\n",
       "  0.9569000005722046,\n",
       "  0.9576600193977356,\n",
       "  0.9591599702835083,\n",
       "  0.959559977054596,\n",
       "  0.9613199830055237,\n",
       "  0.9625399708747864,\n",
       "  0.9630200266838074,\n",
       "  0.9643599987030029,\n",
       "  0.9650800228118896,\n",
       "  0.966480016708374,\n",
       "  0.9670600295066833,\n",
       "  0.9681000113487244,\n",
       "  0.9686800241470337,\n",
       "  0.9697399735450745,\n",
       "  0.9700199961662292,\n",
       "  0.9711800217628479,\n",
       "  0.9717599749565125,\n",
       "  0.972320020198822,\n",
       "  0.972760021686554,\n",
       "  0.9734600186347961,\n",
       "  0.9744799733161926,\n",
       "  0.9747800230979919,\n",
       "  0.9754599928855896,\n",
       "  0.9758599996566772,\n",
       "  0.9761000275611877,\n",
       "  0.9768000245094299,\n",
       "  0.9775199890136719],\n",
       " 'loss': [1.2834657430648804,\n",
       "  0.5124450325965881,\n",
       "  0.39521902799606323,\n",
       "  0.34666934609413147,\n",
       "  0.31750836968421936,\n",
       "  0.2958011031150818,\n",
       "  0.27900588512420654,\n",
       "  0.26507991552352905,\n",
       "  0.25291335582733154,\n",
       "  0.24189233779907227,\n",
       "  0.23200464248657227,\n",
       "  0.222923144698143,\n",
       "  0.2145502120256424,\n",
       "  0.20690228044986725,\n",
       "  0.19970495998859406,\n",
       "  0.1929681897163391,\n",
       "  0.18652747571468353,\n",
       "  0.18067340552806854,\n",
       "  0.17489424347877502,\n",
       "  0.16977417469024658,\n",
       "  0.1644749641418457,\n",
       "  0.1599094569683075,\n",
       "  0.15530234575271606,\n",
       "  0.1510043889284134,\n",
       "  0.14667196571826935,\n",
       "  0.1427895575761795,\n",
       "  0.13901081681251526,\n",
       "  0.13532112538814545,\n",
       "  0.13186636567115784,\n",
       "  0.12863264977931976,\n",
       "  0.12532581388950348,\n",
       "  0.12232533097267151,\n",
       "  0.11939577013254166,\n",
       "  0.11669562757015228,\n",
       "  0.1137651652097702,\n",
       "  0.11115433275699615,\n",
       "  0.1086902916431427,\n",
       "  0.1062961146235466,\n",
       "  0.10405721515417099,\n",
       "  0.10153509676456451,\n",
       "  0.0994952917098999,\n",
       "  0.09745070338249207,\n",
       "  0.09527333080768585,\n",
       "  0.09332779049873352,\n",
       "  0.09129121154546738,\n",
       "  0.08953031152486801,\n",
       "  0.08769015967845917,\n",
       "  0.0859295129776001,\n",
       "  0.08427786082029343,\n",
       "  0.08253870904445648],\n",
       " 'val_accuracy': [0.8655999898910522,\n",
       "  0.8974999785423279,\n",
       "  0.9092000126838684,\n",
       "  0.9161999821662903,\n",
       "  0.9211000204086304,\n",
       "  0.9251999855041504,\n",
       "  0.9297000169754028,\n",
       "  0.9337000250816345,\n",
       "  0.9368000030517578,\n",
       "  0.9380000233650208,\n",
       "  0.9409999847412109,\n",
       "  0.9416999816894531,\n",
       "  0.9438999891281128,\n",
       "  0.9453999996185303,\n",
       "  0.9480000138282776,\n",
       "  0.9505000114440918,\n",
       "  0.95169997215271,\n",
       "  0.9528999924659729,\n",
       "  0.9541000127792358,\n",
       "  0.9550999999046326,\n",
       "  0.9562000036239624,\n",
       "  0.9573000073432922,\n",
       "  0.9584000110626221,\n",
       "  0.9596999883651733,\n",
       "  0.9599000215530396,\n",
       "  0.9606999754905701,\n",
       "  0.9624999761581421,\n",
       "  0.9631999731063843,\n",
       "  0.9639000296592712,\n",
       "  0.9648000001907349,\n",
       "  0.9650999903678894,\n",
       "  0.9657999873161316,\n",
       "  0.9645000100135803,\n",
       "  0.96670001745224,\n",
       "  0.9663000106811523,\n",
       "  0.9661999940872192,\n",
       "  0.9682999849319458,\n",
       "  0.9674999713897705,\n",
       "  0.9682999849319458,\n",
       "  0.968500018119812,\n",
       "  0.9695000052452087,\n",
       "  0.9697999954223633,\n",
       "  0.9696000218391418,\n",
       "  0.9702000021934509,\n",
       "  0.97079998254776,\n",
       "  0.9714999794960022,\n",
       "  0.9711999893188477,\n",
       "  0.9715999960899353,\n",
       "  0.9724000096321106,\n",
       "  0.9729999899864197],\n",
       " 'val_loss': [0.5993039011955261,\n",
       "  0.3932127356529236,\n",
       "  0.332370400428772,\n",
       "  0.3014335334300995,\n",
       "  0.28046417236328125,\n",
       "  0.26564809679985046,\n",
       "  0.2516059875488281,\n",
       "  0.23942133784294128,\n",
       "  0.228723406791687,\n",
       "  0.2215261459350586,\n",
       "  0.21234512329101562,\n",
       "  0.20537415146827698,\n",
       "  0.20187975466251373,\n",
       "  0.19465143978595734,\n",
       "  0.1867169737815857,\n",
       "  0.1820165067911148,\n",
       "  0.17665129899978638,\n",
       "  0.17276319861412048,\n",
       "  0.16840647161006927,\n",
       "  0.16437433660030365,\n",
       "  0.1599218249320984,\n",
       "  0.1556171327829361,\n",
       "  0.15241821110248566,\n",
       "  0.14950121939182281,\n",
       "  0.14674390852451324,\n",
       "  0.1437484174966812,\n",
       "  0.14109814167022705,\n",
       "  0.13741284608840942,\n",
       "  0.13497287034988403,\n",
       "  0.13269536197185516,\n",
       "  0.13085989654064178,\n",
       "  0.12847217917442322,\n",
       "  0.12852704524993896,\n",
       "  0.12429693341255188,\n",
       "  0.123092420399189,\n",
       "  0.12270378321409225,\n",
       "  0.11985176056623459,\n",
       "  0.11870728433132172,\n",
       "  0.11633366346359253,\n",
       "  0.11553610861301422,\n",
       "  0.11368971318006516,\n",
       "  0.111483633518219,\n",
       "  0.11048195511102676,\n",
       "  0.10951639711856842,\n",
       "  0.10865259915590286,\n",
       "  0.10712690651416779,\n",
       "  0.10582633316516876,\n",
       "  0.1056218296289444,\n",
       "  0.10343911498785019,\n",
       "  0.10444143414497375]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.68726</td>\n",
       "      <td>1.283466</td>\n",
       "      <td>0.8656</td>\n",
       "      <td>0.599304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.86962</td>\n",
       "      <td>0.512445</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>0.393213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.89070</td>\n",
       "      <td>0.395219</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.332370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90210</td>\n",
       "      <td>0.346669</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.301434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90982</td>\n",
       "      <td>0.317508</td>\n",
       "      <td>0.9211</td>\n",
       "      <td>0.280464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.91580</td>\n",
       "      <td>0.295801</td>\n",
       "      <td>0.9252</td>\n",
       "      <td>0.265648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.92092</td>\n",
       "      <td>0.279006</td>\n",
       "      <td>0.9297</td>\n",
       "      <td>0.251606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.92454</td>\n",
       "      <td>0.265080</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>0.239421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.92812</td>\n",
       "      <td>0.252913</td>\n",
       "      <td>0.9368</td>\n",
       "      <td>0.228723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.93136</td>\n",
       "      <td>0.241892</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>0.221526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.93394</td>\n",
       "      <td>0.232005</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.212345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.93662</td>\n",
       "      <td>0.222923</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.205374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.93960</td>\n",
       "      <td>0.214550</td>\n",
       "      <td>0.9439</td>\n",
       "      <td>0.201880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.94136</td>\n",
       "      <td>0.206902</td>\n",
       "      <td>0.9454</td>\n",
       "      <td>0.194651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.94342</td>\n",
       "      <td>0.199705</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.186717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.94542</td>\n",
       "      <td>0.192968</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.182017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.94716</td>\n",
       "      <td>0.186527</td>\n",
       "      <td>0.9517</td>\n",
       "      <td>0.176651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.94870</td>\n",
       "      <td>0.180673</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.172763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.94986</td>\n",
       "      <td>0.174894</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.168406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.95154</td>\n",
       "      <td>0.169774</td>\n",
       "      <td>0.9551</td>\n",
       "      <td>0.164374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.95288</td>\n",
       "      <td>0.164475</td>\n",
       "      <td>0.9562</td>\n",
       "      <td>0.159922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.95402</td>\n",
       "      <td>0.159909</td>\n",
       "      <td>0.9573</td>\n",
       "      <td>0.155617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.95532</td>\n",
       "      <td>0.155302</td>\n",
       "      <td>0.9584</td>\n",
       "      <td>0.152418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.95690</td>\n",
       "      <td>0.151004</td>\n",
       "      <td>0.9597</td>\n",
       "      <td>0.149501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.95766</td>\n",
       "      <td>0.146672</td>\n",
       "      <td>0.9599</td>\n",
       "      <td>0.146744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.95916</td>\n",
       "      <td>0.142790</td>\n",
       "      <td>0.9607</td>\n",
       "      <td>0.143748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.95956</td>\n",
       "      <td>0.139011</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.141098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.96132</td>\n",
       "      <td>0.135321</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.137413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.96254</td>\n",
       "      <td>0.131866</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>0.134973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.96302</td>\n",
       "      <td>0.128633</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>0.132695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.96436</td>\n",
       "      <td>0.125326</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>0.130860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.96508</td>\n",
       "      <td>0.122325</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>0.128472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.96648</td>\n",
       "      <td>0.119396</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.128527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.96706</td>\n",
       "      <td>0.116696</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.124297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.96810</td>\n",
       "      <td>0.113765</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.123092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.96868</td>\n",
       "      <td>0.111154</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.122704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.96974</td>\n",
       "      <td>0.108690</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.119852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.97002</td>\n",
       "      <td>0.106296</td>\n",
       "      <td>0.9675</td>\n",
       "      <td>0.118707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.97118</td>\n",
       "      <td>0.104057</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.116334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.97176</td>\n",
       "      <td>0.101535</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.115536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.97232</td>\n",
       "      <td>0.099495</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.113690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.97276</td>\n",
       "      <td>0.097451</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.111484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.97346</td>\n",
       "      <td>0.095273</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.110482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.97448</td>\n",
       "      <td>0.093328</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.109516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.97478</td>\n",
       "      <td>0.091291</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>0.108653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.97546</td>\n",
       "      <td>0.089530</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>0.107127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.97586</td>\n",
       "      <td>0.087690</td>\n",
       "      <td>0.9712</td>\n",
       "      <td>0.105826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.97610</td>\n",
       "      <td>0.085930</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>0.105622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.97680</td>\n",
       "      <td>0.084278</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.103439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.97752</td>\n",
       "      <td>0.082539</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.104441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy      loss  val_accuracy  val_loss\n",
       "0    0.68726  1.283466        0.8656  0.599304\n",
       "1    0.86962  0.512445        0.8975  0.393213\n",
       "2    0.89070  0.395219        0.9092  0.332370\n",
       "3    0.90210  0.346669        0.9162  0.301434\n",
       "4    0.90982  0.317508        0.9211  0.280464\n",
       "5    0.91580  0.295801        0.9252  0.265648\n",
       "6    0.92092  0.279006        0.9297  0.251606\n",
       "7    0.92454  0.265080        0.9337  0.239421\n",
       "8    0.92812  0.252913        0.9368  0.228723\n",
       "9    0.93136  0.241892        0.9380  0.221526\n",
       "10   0.93394  0.232005        0.9410  0.212345\n",
       "11   0.93662  0.222923        0.9417  0.205374\n",
       "12   0.93960  0.214550        0.9439  0.201880\n",
       "13   0.94136  0.206902        0.9454  0.194651\n",
       "14   0.94342  0.199705        0.9480  0.186717\n",
       "15   0.94542  0.192968        0.9505  0.182017\n",
       "16   0.94716  0.186527        0.9517  0.176651\n",
       "17   0.94870  0.180673        0.9529  0.172763\n",
       "18   0.94986  0.174894        0.9541  0.168406\n",
       "19   0.95154  0.169774        0.9551  0.164374\n",
       "20   0.95288  0.164475        0.9562  0.159922\n",
       "21   0.95402  0.159909        0.9573  0.155617\n",
       "22   0.95532  0.155302        0.9584  0.152418\n",
       "23   0.95690  0.151004        0.9597  0.149501\n",
       "24   0.95766  0.146672        0.9599  0.146744\n",
       "25   0.95916  0.142790        0.9607  0.143748\n",
       "26   0.95956  0.139011        0.9625  0.141098\n",
       "27   0.96132  0.135321        0.9632  0.137413\n",
       "28   0.96254  0.131866        0.9639  0.134973\n",
       "29   0.96302  0.128633        0.9648  0.132695\n",
       "30   0.96436  0.125326        0.9651  0.130860\n",
       "31   0.96508  0.122325        0.9658  0.128472\n",
       "32   0.96648  0.119396        0.9645  0.128527\n",
       "33   0.96706  0.116696        0.9667  0.124297\n",
       "34   0.96810  0.113765        0.9663  0.123092\n",
       "35   0.96868  0.111154        0.9662  0.122704\n",
       "36   0.96974  0.108690        0.9683  0.119852\n",
       "37   0.97002  0.106296        0.9675  0.118707\n",
       "38   0.97118  0.104057        0.9683  0.116334\n",
       "39   0.97176  0.101535        0.9685  0.115536\n",
       "40   0.97232  0.099495        0.9695  0.113690\n",
       "41   0.97276  0.097451        0.9698  0.111484\n",
       "42   0.97346  0.095273        0.9696  0.110482\n",
       "43   0.97448  0.093328        0.9702  0.109516\n",
       "44   0.97478  0.091291        0.9708  0.108653\n",
       "45   0.97546  0.089530        0.9715  0.107127\n",
       "46   0.97586  0.087690        0.9712  0.105826\n",
       "47   0.97610  0.085930        0.9716  0.105622\n",
       "48   0.97680  0.084278        0.9724  0.103439\n",
       "49   0.97752  0.082539        0.9730  0.104441"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  6/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9872 - loss: 0.0802"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 21/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9861 - loss: 0.0773"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9643 - loss: 0.1234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1057697981595993, 0.9685999751091003]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yporq\\AppData\\Local\\Temp\\ipykernel_40448\\1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.001, 0.003, 0.   , 0.   , 0.   , 0.996, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 11/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 6ms/step "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yporq\\AppData\\Local\\Temp\\ipykernel_40448\\1084033691.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.any(np.isnan(X_train)))\n",
    "print(np.any(np.isnan(X_valid)))\n",
    "print(np.any(np.isnan(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m  4/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 7.2956 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 2.8335 - val_loss: 0.5862\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.5679 - val_loss: 0.5420\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.4573 - val_loss: 0.5650\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.4725 - val_loss: 0.5617\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.4352 - val_loss: 0.5181\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.4122 - val_loss: 0.4780\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - loss: 0.4106 - val_loss: 0.4414\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 48ms/step - loss: 0.3929 - val_loss: 0.4030\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 43ms/step - loss: 0.3940 - val_loss: 0.3815\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - loss: 0.3849 - val_loss: 0.3802\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 48ms/step - loss: 0.3802 - val_loss: 0.3834\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 47ms/step - loss: 0.3497 - val_loss: 0.3795\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - loss: 0.3581 - val_loss: 0.3697\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - loss: 0.3628 - val_loss: 0.3761\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - loss: 0.3473 - val_loss: 0.3687\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - loss: 0.3450 - val_loss: 0.3635\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 48ms/step - loss: 0.3523 - val_loss: 0.3635\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 59ms/step - loss: 0.3553 - val_loss: 0.3732\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - loss: 0.3547 - val_loss: 0.3564\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 48ms/step - loss: 0.3410 - val_loss: 0.3585\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.SGD(clipnorm=1)\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = optimizer) # con optimizer = \"sgd\" aparece la explosión del gradiente y nan's \n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">303</span> (1.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m303\u001b[0m (1.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  4/162\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.4619  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.3665\n",
      "0.355655699968338\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.2820868 ],\n",
       "       [0.92377836],\n",
       "       [4.7062798 ],\n",
       "       [2.810796  ],\n",
       "       [3.0234938 ]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown variable: <Variable path=sequential_2/dense_6/kernel, shape=(8, 30), dtype=float32, value=[[-2.18793005e-02  4.07734156e-01 -2.97670126e-01  1.87464416e-01\n  -1.32558763e-01  4.06811148e-01  2.16701910e-01  2.54678607e-01\n   4.38542187e-01 -1.17533326e-01  2.98744708e-01  1.01247065e-01\n   6.54267073e-02  1.28909826e-01  2.39936560e-01  1.25599667e-01\n   6.44657835e-02 -8.35153013e-02  2.50727117e-01  2.52145648e-01\n   1.19248487e-01 -3.82027149e-01  1.79768857e-02 -2.61835128e-01\n   7.09031373e-02 -1.38915377e-03  5.12432575e-01 -2.39203304e-01\n  -3.19583490e-02  4.78183888e-02]\n [-4.90427501e-02  1.86125100e-01 -1.89684212e-01 -2.75941551e-01\n   1.43409118e-01 -2.49831915e-01 -9.81945172e-02  2.56912321e-01\n   1.43044144e-01  3.45092386e-01  7.95271322e-02  1.38456494e-01\n   3.31705898e-01 -3.18551213e-01  1.55378446e-01 -5.95669523e-02\n  -7.66777769e-02  1.70220193e-02  7.67463818e-02  2.79445201e-02\n   1.29705459e-01  2.41936088e-01  3.72581594e-02  2.70442009e-01\n   4.48815860e-02  4.05303717e-01  4.30379361e-02 -2.34660774e-01\n   6.96723238e-02  1.59820728e-03]\n [ 6.39407039e-02 -4.16296721e-01 -1.61646809e-02  3.07248682e-01\n  -5.91400191e-02 -4.19394284e-01 -2.13148687e-02  6.26951382e-02\n   3.31243157e-01  3.30442995e-01 -1.40482187e-01 -5.97409666e-01\n   3.17466795e-01 -3.65033746e-01  5.16184010e-02  6.47798553e-02\n   5.53036034e-01  1.38394684e-01  6.75490275e-02 -9.71414670e-02\n   1.35710463e-03  1.50818601e-01  4.12289687e-02  9.93723273e-02\n  -1.43866539e-01  2.92830259e-01  9.95813161e-02 -1.98997736e-01\n   1.53390497e-01 -2.61094987e-01]\n [ 9.85699594e-02  4.03408527e-01  2.73609281e-01  2.99876720e-01\n  -5.15757222e-03  2.08737925e-01 -1.89207956e-01  2.88492203e-01\n  -9.60477516e-02 -1.13632262e-01  1.00499414e-01  2.96968937e-01\n  -3.97487544e-04 -5.42088673e-02  4.90233451e-01  7.76248872e-02\n  -8.19817558e-02 -1.07708819e-01  2.37271577e-01  9.78373885e-02\n  -3.13026726e-01  2.15008914e-01 -2.46964678e-01 -1.33717299e-01\n  -3.17849189e-01 -2.21667022e-01  4.78926271e-01  1.04627304e-01\n   1.74680993e-01  4.44612876e-02]\n [ 3.09716025e-03  3.83146107e-01  2.97839463e-01  1.68203369e-01\n   3.02270651e-01 -1.60428986e-01 -6.67300895e-02 -2.60534316e-01\n  -8.72851834e-02  1.81864366e-01 -5.29100373e-03  1.10479295e-01\n   1.33393601e-01  2.40496933e-01 -8.03257746e-04 -2.42786482e-01\n   4.21232451e-03  3.51004153e-02  4.26655829e-01 -3.12344506e-02\n   6.75615221e-02 -9.70626324e-02 -2.25537285e-01  2.04552531e-01\n  -8.48023873e-03 -2.72062331e-01  2.88779326e-02  3.17036986e-01\n  -4.46837768e-03  3.40972543e-01]\n [-2.98052371e-01 -2.72063911e-01 -2.69576371e-01 -9.43000689e-02\n   2.19613254e-01 -1.28716379e-01 -1.22389898e-01  5.56887574e-02\n  -6.14619732e-01 -5.99764824e-01 -3.15913588e-01 -6.85227096e-01\n   1.50425360e-01 -2.66253680e-01 -1.02084406e-01  1.26062974e-01\n   2.14242935e-01 -6.37427047e-02 -3.52955312e-01 -1.17386937e+00\n  -2.69588530e-02  2.73556679e-01 -3.25124115e-01 -8.11758116e-02\n  -1.25873655e-01 -2.92235371e-02 -5.11882365e-01 -2.66833454e-01\n  -2.58450061e-01  3.82778853e-01]\n [-3.83508295e-01 -1.04837403e-01  1.20523557e-01 -3.41612756e-01\n   2.02606186e-01  1.44553229e-01 -4.96766508e-01 -3.72236460e-01\n  -2.25019217e-01 -1.23761542e-01 -1.11742161e-01 -1.39351666e-01\n   6.25459850e-02  5.55577949e-02  1.89009890e-01  5.72378114e-02\n   1.56962276e-01 -4.58924860e-01  2.40828305e-01 -7.56108224e-01\n  -1.31011829e-02  1.76713914e-01 -3.95636082e-01  3.36352289e-01\n  -2.44881496e-01  3.55279967e-02 -1.01280466e-01  3.58292609e-01\n   3.42026263e-01  3.92179996e-01]\n [-1.97113771e-02 -9.03295428e-02  3.32388759e-01 -1.24587253e-01\n   4.39118981e-01 -1.69731110e-01 -1.46553889e-01 -3.95660758e-01\n  -1.97858393e-01 -3.84644270e-02 -1.36091650e-01 -6.85215443e-02\n  -2.47198582e-01  1.03911094e-01  7.03814179e-02 -2.17015833e-01\n   1.68071449e-01 -3.04595083e-01  2.95346260e-01 -6.97714031e-01\n  -2.25860670e-01 -6.61956370e-02 -4.33935642e-01 -1.42847444e-03\n   4.72356737e-01  7.25068375e-02 -1.97154909e-01 -2.32629403e-01\n  -5.06972551e-01 -5.14594555e-01]]>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m checkpoint_cb \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:329\u001b[0m, in \u001b[0;36mBaseOptimizer._check_variables_are_known\u001b[1;34m(self, variables)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_key(v) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables_indices:\n\u001b[1;32m--> 329\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    330\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This optimizer can only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe called for the variables it was originally built with. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen working with a new set of variables, you should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecreate a new optimizer instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown variable: <Variable path=sequential_2/dense_6/kernel, shape=(8, 30), dtype=float32, value=[[-2.18793005e-02  4.07734156e-01 -2.97670126e-01  1.87464416e-01\n  -1.32558763e-01  4.06811148e-01  2.16701910e-01  2.54678607e-01\n   4.38542187e-01 -1.17533326e-01  2.98744708e-01  1.01247065e-01\n   6.54267073e-02  1.28909826e-01  2.39936560e-01  1.25599667e-01\n   6.44657835e-02 -8.35153013e-02  2.50727117e-01  2.52145648e-01\n   1.19248487e-01 -3.82027149e-01  1.79768857e-02 -2.61835128e-01\n   7.09031373e-02 -1.38915377e-03  5.12432575e-01 -2.39203304e-01\n  -3.19583490e-02  4.78183888e-02]\n [-4.90427501e-02  1.86125100e-01 -1.89684212e-01 -2.75941551e-01\n   1.43409118e-01 -2.49831915e-01 -9.81945172e-02  2.56912321e-01\n   1.43044144e-01  3.45092386e-01  7.95271322e-02  1.38456494e-01\n   3.31705898e-01 -3.18551213e-01  1.55378446e-01 -5.95669523e-02\n  -7.66777769e-02  1.70220193e-02  7.67463818e-02  2.79445201e-02\n   1.29705459e-01  2.41936088e-01  3.72581594e-02  2.70442009e-01\n   4.48815860e-02  4.05303717e-01  4.30379361e-02 -2.34660774e-01\n   6.96723238e-02  1.59820728e-03]\n [ 6.39407039e-02 -4.16296721e-01 -1.61646809e-02  3.07248682e-01\n  -5.91400191e-02 -4.19394284e-01 -2.13148687e-02  6.26951382e-02\n   3.31243157e-01  3.30442995e-01 -1.40482187e-01 -5.97409666e-01\n   3.17466795e-01 -3.65033746e-01  5.16184010e-02  6.47798553e-02\n   5.53036034e-01  1.38394684e-01  6.75490275e-02 -9.71414670e-02\n   1.35710463e-03  1.50818601e-01  4.12289687e-02  9.93723273e-02\n  -1.43866539e-01  2.92830259e-01  9.95813161e-02 -1.98997736e-01\n   1.53390497e-01 -2.61094987e-01]\n [ 9.85699594e-02  4.03408527e-01  2.73609281e-01  2.99876720e-01\n  -5.15757222e-03  2.08737925e-01 -1.89207956e-01  2.88492203e-01\n  -9.60477516e-02 -1.13632262e-01  1.00499414e-01  2.96968937e-01\n  -3.97487544e-04 -5.42088673e-02  4.90233451e-01  7.76248872e-02\n  -8.19817558e-02 -1.07708819e-01  2.37271577e-01  9.78373885e-02\n  -3.13026726e-01  2.15008914e-01 -2.46964678e-01 -1.33717299e-01\n  -3.17849189e-01 -2.21667022e-01  4.78926271e-01  1.04627304e-01\n   1.74680993e-01  4.44612876e-02]\n [ 3.09716025e-03  3.83146107e-01  2.97839463e-01  1.68203369e-01\n   3.02270651e-01 -1.60428986e-01 -6.67300895e-02 -2.60534316e-01\n  -8.72851834e-02  1.81864366e-01 -5.29100373e-03  1.10479295e-01\n   1.33393601e-01  2.40496933e-01 -8.03257746e-04 -2.42786482e-01\n   4.21232451e-03  3.51004153e-02  4.26655829e-01 -3.12344506e-02\n   6.75615221e-02 -9.70626324e-02 -2.25537285e-01  2.04552531e-01\n  -8.48023873e-03 -2.72062331e-01  2.88779326e-02  3.17036986e-01\n  -4.46837768e-03  3.40972543e-01]\n [-2.98052371e-01 -2.72063911e-01 -2.69576371e-01 -9.43000689e-02\n   2.19613254e-01 -1.28716379e-01 -1.22389898e-01  5.56887574e-02\n  -6.14619732e-01 -5.99764824e-01 -3.15913588e-01 -6.85227096e-01\n   1.50425360e-01 -2.66253680e-01 -1.02084406e-01  1.26062974e-01\n   2.14242935e-01 -6.37427047e-02 -3.52955312e-01 -1.17386937e+00\n  -2.69588530e-02  2.73556679e-01 -3.25124115e-01 -8.11758116e-02\n  -1.25873655e-01 -2.92235371e-02 -5.11882365e-01 -2.66833454e-01\n  -2.58450061e-01  3.82778853e-01]\n [-3.83508295e-01 -1.04837403e-01  1.20523557e-01 -3.41612756e-01\n   2.02606186e-01  1.44553229e-01 -4.96766508e-01 -3.72236460e-01\n  -2.25019217e-01 -1.23761542e-01 -1.11742161e-01 -1.39351666e-01\n   6.25459850e-02  5.55577949e-02  1.89009890e-01  5.72378114e-02\n   1.56962276e-01 -4.58924860e-01  2.40828305e-01 -7.56108224e-01\n  -1.31011829e-02  1.76713914e-01 -3.95636082e-01  3.36352289e-01\n  -2.44881496e-01  3.55279967e-02 -1.01280466e-01  3.58292609e-01\n   3.42026263e-01  3.92179996e-01]\n [-1.97113771e-02 -9.03295428e-02  3.32388759e-01 -1.24587253e-01\n   4.39118981e-01 -1.69731110e-01 -1.46553889e-01 -3.95660758e-01\n  -1.97858393e-01 -3.84644270e-02 -1.36091650e-01 -6.85215443e-02\n  -2.47198582e-01  1.03911094e-01  7.03814179e-02 -2.17015833e-01\n   1.68071449e-01 -3.04595083e-01  2.95346260e-01 -6.97714031e-01\n  -2.25860670e-01 -6.61956370e-02 -4.33935642e-01 -1.42847444e-03\n   4.72356737e-01  7.25068375e-02 -1.97154909e-01 -2.32629403e-01\n  -5.06972551e-01 -5.14594555e-01]]>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance."
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3366 - val_loss: 0.3556\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3356 - val_loss: 0.3625\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3352 - val_loss: 0.3562\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3349 - val_loss: 0.3583\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3341 - val_loss: 0.3520\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3328 - val_loss: 0.3556\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.3512\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.3579\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3324 - val_loss: 0.3559\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3309 - val_loss: 0.3505\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3303 - val_loss: 0.3482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3288 - val_loss: 0.3528\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3286 - val_loss: 0.3525\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3284 - val_loss: 0.3479\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3276 - val_loss: 0.3523\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3276 - val_loss: 0.3486\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3271 - val_loss: 0.3461\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3262 - val_loss: 0.3519\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3262 - val_loss: 0.3521\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3256 - val_loss: 0.3547\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=20,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Ruta de logs (usa fecha para evitar sobrescribir)\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow --user\n",
    "#!pip install keras --user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yporq\\AppData\\Local\\Temp\\ipykernel_28740\\4213989973.py:2: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)  # o más directamente:\n",
    "tf.compat.v1.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yporq\\AppData\\Local\\Temp\\ipykernel_28740\\3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Flatten name=flatten_1, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*28*28 + 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.5118 - loss: 1.7313 - val_accuracy: 0.8684 - val_loss: 0.5889\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.8623 - loss: 0.5631 - val_accuracy: 0.8983 - val_loss: 0.3892\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8880 - loss: 0.4136 - val_accuracy: 0.9082 - val_loss: 0.3319\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8993 - loss: 0.3597 - val_accuracy: 0.9154 - val_loss: 0.3021\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9085 - loss: 0.3259 - val_accuracy: 0.9194 - val_loss: 0.2847\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.9144 - loss: 0.3032 - val_accuracy: 0.9233 - val_loss: 0.2655\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9187 - loss: 0.2876 - val_accuracy: 0.9260 - val_loss: 0.2522\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9235 - loss: 0.2702 - val_accuracy: 0.9288 - val_loss: 0.2424\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9278 - loss: 0.2544 - val_accuracy: 0.9319 - val_loss: 0.2344\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9292 - loss: 0.2482 - val_accuracy: 0.9365 - val_loss: 0.2229\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9338 - loss: 0.2360 - val_accuracy: 0.9380 - val_loss: 0.2152\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.9374 - loss: 0.2223 - val_accuracy: 0.9406 - val_loss: 0.2089\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 37ms/step - accuracy: 0.9401 - loss: 0.2157 - val_accuracy: 0.9425 - val_loss: 0.2008\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 49ms/step - accuracy: 0.9399 - loss: 0.2118 - val_accuracy: 0.9445 - val_loss: 0.1965\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9428 - loss: 0.2016 - val_accuracy: 0.9472 - val_loss: 0.1891\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - accuracy: 0.9448 - loss: 0.1966 - val_accuracy: 0.9498 - val_loss: 0.1837\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 59ms/step - accuracy: 0.9450 - loss: 0.1920 - val_accuracy: 0.9486 - val_loss: 0.1805\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 72ms/step - accuracy: 0.9478 - loss: 0.1824 - val_accuracy: 0.9509 - val_loss: 0.1761\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.9487 - loss: 0.1773 - val_accuracy: 0.9523 - val_loss: 0.1713\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - accuracy: 0.9489 - loss: 0.1773 - val_accuracy: 0.9532 - val_loss: 0.1676\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - accuracy: 0.9520 - loss: 0.1650 - val_accuracy: 0.9546 - val_loss: 0.1632\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - accuracy: 0.9536 - loss: 0.1614 - val_accuracy: 0.9557 - val_loss: 0.1603\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - accuracy: 0.9546 - loss: 0.1583 - val_accuracy: 0.9565 - val_loss: 0.1562\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 45ms/step - accuracy: 0.9548 - loss: 0.1567 - val_accuracy: 0.9572 - val_loss: 0.1538\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9561 - loss: 0.1509 - val_accuracy: 0.9580 - val_loss: 0.1503\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9577 - loss: 0.1461 - val_accuracy: 0.9586 - val_loss: 0.1485\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - accuracy: 0.9588 - loss: 0.1429 - val_accuracy: 0.9589 - val_loss: 0.1450\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - accuracy: 0.9602 - loss: 0.1372 - val_accuracy: 0.9604 - val_loss: 0.1432\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9600 - loss: 0.1396 - val_accuracy: 0.9611 - val_loss: 0.1401\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9631 - loss: 0.1330 - val_accuracy: 0.9613 - val_loss: 0.1388\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.9627 - loss: 0.1299 - val_accuracy: 0.9625 - val_loss: 0.1354\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9648 - loss: 0.1258 - val_accuracy: 0.9635 - val_loss: 0.1327\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9646 - loss: 0.1234 - val_accuracy: 0.9637 - val_loss: 0.1312\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9674 - loss: 0.1159 - val_accuracy: 0.9640 - val_loss: 0.1288\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9661 - loss: 0.1214 - val_accuracy: 0.9645 - val_loss: 0.1277\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9688 - loss: 0.1125 - val_accuracy: 0.9647 - val_loss: 0.1256\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9686 - loss: 0.1125 - val_accuracy: 0.9658 - val_loss: 0.1241\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9694 - loss: 0.1089 - val_accuracy: 0.9657 - val_loss: 0.1231\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9698 - loss: 0.1074 - val_accuracy: 0.9666 - val_loss: 0.1213\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9704 - loss: 0.1033 - val_accuracy: 0.9669 - val_loss: 0.1201\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9724 - loss: 0.0992 - val_accuracy: 0.9678 - val_loss: 0.1177\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9719 - loss: 0.1023 - val_accuracy: 0.9683 - val_loss: 0.1161\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9732 - loss: 0.0988 - val_accuracy: 0.9682 - val_loss: 0.1154\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9731 - loss: 0.0972 - val_accuracy: 0.9685 - val_loss: 0.1135\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9737 - loss: 0.0950 - val_accuracy: 0.9693 - val_loss: 0.1125\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9747 - loss: 0.0915 - val_accuracy: 0.9683 - val_loss: 0.1121\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9759 - loss: 0.0884 - val_accuracy: 0.9703 - val_loss: 0.1102\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9757 - loss: 0.0897 - val_accuracy: 0.9698 - val_loss: 0.1094\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9751 - loss: 0.0881 - val_accuracy: 0.9693 - val_loss: 0.1083\n",
      "Epoch 50/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9763 - loss: 0.0880 - val_accuracy: 0.9706 - val_loss: 0.1067\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val), # validation_split = 0.1\n",
    "    callbacks=[tensorboard_callback] #aquí guardamos los datos de entrenamiento(loss, accuracy, val_loss... en logs/fit/)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.9770 - loss: 0.0864 - val_accuracy: 0.9681 - val_loss: 0.1098\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9771 - loss: 0.0839 - val_accuracy: 0.9709 - val_loss: 0.1038\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9784 - loss: 0.0785 - val_accuracy: 0.9710 - val_loss: 0.1017\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9803 - loss: 0.0748 - val_accuracy: 0.9720 - val_loss: 0.1004\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.9802 - loss: 0.0713 - val_accuracy: 0.9730 - val_loss: 0.0984\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.9813 - loss: 0.0704 - val_accuracy: 0.9732 - val_loss: 0.0989\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.9826 - loss: 0.0677 - val_accuracy: 0.9737 - val_loss: 0.0966\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9829 - loss: 0.0635 - val_accuracy: 0.9731 - val_loss: 0.0973\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9825 - loss: 0.0641 - val_accuracy: 0.9715 - val_loss: 0.1000\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.9841 - loss: 0.0613 - val_accuracy: 0.9736 - val_loss: 0.0935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c53c3cf210>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 'auto', 'epochs': 50, 'steps': 391}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.6951799988746643,\n",
       "  0.8712000250816345,\n",
       "  0.8920000195503235,\n",
       "  0.9025599956512451,\n",
       "  0.909600019454956,\n",
       "  0.9150599837303162,\n",
       "  0.9207000136375427,\n",
       "  0.9243999719619751,\n",
       "  0.9281799793243408,\n",
       "  0.9313600063323975,\n",
       "  0.934499979019165,\n",
       "  0.9367600083351135,\n",
       "  0.9389399886131287,\n",
       "  0.9409599900245667,\n",
       "  0.9428600072860718,\n",
       "  0.9447799921035767,\n",
       "  0.9460600018501282,\n",
       "  0.9477999806404114,\n",
       "  0.9486799836158752,\n",
       "  0.9507399797439575,\n",
       "  0.9517599940299988,\n",
       "  0.9530799984931946,\n",
       "  0.9549000263214111,\n",
       "  0.955839991569519,\n",
       "  0.9569399952888489,\n",
       "  0.958299994468689,\n",
       "  0.959559977054596,\n",
       "  0.960319995880127,\n",
       "  0.9618600010871887,\n",
       "  0.962939977645874,\n",
       "  0.9632400274276733,\n",
       "  0.9645400047302246,\n",
       "  0.965399980545044,\n",
       "  0.9659199714660645,\n",
       "  0.9674199819564819,\n",
       "  0.9680399894714355,\n",
       "  0.9684399962425232,\n",
       "  0.9693800210952759,\n",
       "  0.9697800278663635,\n",
       "  0.9706000089645386,\n",
       "  0.9717400074005127,\n",
       "  0.9718999862670898,\n",
       "  0.9726200103759766,\n",
       "  0.9734799861907959,\n",
       "  0.9739000201225281,\n",
       "  0.9746599793434143,\n",
       "  0.9755200147628784,\n",
       "  0.9755600094795227,\n",
       "  0.976140022277832,\n",
       "  0.9768999814987183],\n",
       " 'loss': [1.253912091255188,\n",
       "  0.5076869130134583,\n",
       "  0.3944292664527893,\n",
       "  0.3476637005805969,\n",
       "  0.3186607360839844,\n",
       "  0.29778847098350525,\n",
       "  0.2804984450340271,\n",
       "  0.26589134335517883,\n",
       "  0.2536153793334961,\n",
       "  0.24273839592933655,\n",
       "  0.23256908357143402,\n",
       "  0.22375744581222534,\n",
       "  0.21558202803134918,\n",
       "  0.20786872506141663,\n",
       "  0.20092087984085083,\n",
       "  0.19427257776260376,\n",
       "  0.18803368508815765,\n",
       "  0.18226568400859833,\n",
       "  0.17673516273498535,\n",
       "  0.1713884025812149,\n",
       "  0.166616290807724,\n",
       "  0.16176855564117432,\n",
       "  0.157351553440094,\n",
       "  0.1531589776277542,\n",
       "  0.14920887351036072,\n",
       "  0.14512886106967926,\n",
       "  0.1415550708770752,\n",
       "  0.13799290359020233,\n",
       "  0.1345224231481552,\n",
       "  0.13122500479221344,\n",
       "  0.12834717333316803,\n",
       "  0.1251116544008255,\n",
       "  0.12224740535020828,\n",
       "  0.11943504214286804,\n",
       "  0.116664357483387,\n",
       "  0.11427651345729828,\n",
       "  0.11170760542154312,\n",
       "  0.10896100848913193,\n",
       "  0.10674706101417542,\n",
       "  0.10448850691318512,\n",
       "  0.1023392453789711,\n",
       "  0.10019924491643906,\n",
       "  0.09812351316213608,\n",
       "  0.09615366160869598,\n",
       "  0.09406448900699615,\n",
       "  0.09224370121955872,\n",
       "  0.0903957411646843,\n",
       "  0.08872652053833008,\n",
       "  0.0870792418718338,\n",
       "  0.08531903475522995],\n",
       " 'val_accuracy': [0.868399977684021,\n",
       "  0.8982999920845032,\n",
       "  0.9082000255584717,\n",
       "  0.9154000282287598,\n",
       "  0.9193999767303467,\n",
       "  0.92330002784729,\n",
       "  0.9259999990463257,\n",
       "  0.9287999868392944,\n",
       "  0.9319000244140625,\n",
       "  0.9365000128746033,\n",
       "  0.9380000233650208,\n",
       "  0.9405999779701233,\n",
       "  0.9424999952316284,\n",
       "  0.9445000290870667,\n",
       "  0.9472000002861023,\n",
       "  0.9498000144958496,\n",
       "  0.9485999941825867,\n",
       "  0.9509000182151794,\n",
       "  0.9523000121116638,\n",
       "  0.9531999826431274,\n",
       "  0.9545999765396118,\n",
       "  0.9556999802589417,\n",
       "  0.9564999938011169,\n",
       "  0.9571999907493591,\n",
       "  0.9580000042915344,\n",
       "  0.9585999846458435,\n",
       "  0.958899974822998,\n",
       "  0.9603999853134155,\n",
       "  0.9610999822616577,\n",
       "  0.9613000154495239,\n",
       "  0.9624999761581421,\n",
       "  0.9635000228881836,\n",
       "  0.963699996471405,\n",
       "  0.9639999866485596,\n",
       "  0.9645000100135803,\n",
       "  0.9646999835968018,\n",
       "  0.9657999873161316,\n",
       "  0.9656999707221985,\n",
       "  0.9666000008583069,\n",
       "  0.9668999910354614,\n",
       "  0.9678000211715698,\n",
       "  0.9682999849319458,\n",
       "  0.9682000279426575,\n",
       "  0.968500018119812,\n",
       "  0.9692999720573425,\n",
       "  0.9682999849319458,\n",
       "  0.970300018787384,\n",
       "  0.9697999954223633,\n",
       "  0.9692999720573425,\n",
       "  0.9706000089645386],\n",
       " 'val_loss': [0.5888599157333374,\n",
       "  0.3892429769039154,\n",
       "  0.3318827450275421,\n",
       "  0.3021281063556671,\n",
       "  0.28470584750175476,\n",
       "  0.265531450510025,\n",
       "  0.2522396445274353,\n",
       "  0.24235248565673828,\n",
       "  0.2343684583902359,\n",
       "  0.22290287911891937,\n",
       "  0.2152053415775299,\n",
       "  0.2088613510131836,\n",
       "  0.20080868899822235,\n",
       "  0.196541428565979,\n",
       "  0.1890890896320343,\n",
       "  0.1837470829486847,\n",
       "  0.18052791059017181,\n",
       "  0.17608368396759033,\n",
       "  0.17130811512470245,\n",
       "  0.16759954392910004,\n",
       "  0.16324439644813538,\n",
       "  0.16025976836681366,\n",
       "  0.15624941885471344,\n",
       "  0.15375974774360657,\n",
       "  0.15034975111484528,\n",
       "  0.14849627017974854,\n",
       "  0.14498364925384521,\n",
       "  0.14319108426570892,\n",
       "  0.14013616740703583,\n",
       "  0.1388200968503952,\n",
       "  0.1354348063468933,\n",
       "  0.13273830711841583,\n",
       "  0.1312197744846344,\n",
       "  0.12882675230503082,\n",
       "  0.12772275507450104,\n",
       "  0.12558946013450623,\n",
       "  0.12406770884990692,\n",
       "  0.1230601817369461,\n",
       "  0.12125928699970245,\n",
       "  0.12008217722177505,\n",
       "  0.11774494498968124,\n",
       "  0.11609283089637756,\n",
       "  0.11540334671735764,\n",
       "  0.11347819864749908,\n",
       "  0.11253420263528824,\n",
       "  0.11206192523241043,\n",
       "  0.11016317456960678,\n",
       "  0.10941947996616364,\n",
       "  0.108260877430439,\n",
       "  0.10670865327119827]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.6951799988746643,\n",
       "  0.8712000250816345,\n",
       "  0.8920000195503235,\n",
       "  0.9025599956512451,\n",
       "  0.909600019454956,\n",
       "  0.9150599837303162,\n",
       "  0.9207000136375427,\n",
       "  0.9243999719619751,\n",
       "  0.9281799793243408,\n",
       "  0.9313600063323975,\n",
       "  0.934499979019165,\n",
       "  0.9367600083351135,\n",
       "  0.9389399886131287,\n",
       "  0.9409599900245667,\n",
       "  0.9428600072860718,\n",
       "  0.9447799921035767,\n",
       "  0.9460600018501282,\n",
       "  0.9477999806404114,\n",
       "  0.9486799836158752,\n",
       "  0.9507399797439575,\n",
       "  0.9517599940299988,\n",
       "  0.9530799984931946,\n",
       "  0.9549000263214111,\n",
       "  0.955839991569519,\n",
       "  0.9569399952888489,\n",
       "  0.958299994468689,\n",
       "  0.959559977054596,\n",
       "  0.960319995880127,\n",
       "  0.9618600010871887,\n",
       "  0.962939977645874,\n",
       "  0.9632400274276733,\n",
       "  0.9645400047302246,\n",
       "  0.965399980545044,\n",
       "  0.9659199714660645,\n",
       "  0.9674199819564819,\n",
       "  0.9680399894714355,\n",
       "  0.9684399962425232,\n",
       "  0.9693800210952759,\n",
       "  0.9697800278663635,\n",
       "  0.9706000089645386,\n",
       "  0.9717400074005127,\n",
       "  0.9718999862670898,\n",
       "  0.9726200103759766,\n",
       "  0.9734799861907959,\n",
       "  0.9739000201225281,\n",
       "  0.9746599793434143,\n",
       "  0.9755200147628784,\n",
       "  0.9755600094795227,\n",
       "  0.976140022277832,\n",
       "  0.9768999814987183],\n",
       " 'loss': [1.253912091255188,\n",
       "  0.5076869130134583,\n",
       "  0.3944292664527893,\n",
       "  0.3476637005805969,\n",
       "  0.3186607360839844,\n",
       "  0.29778847098350525,\n",
       "  0.2804984450340271,\n",
       "  0.26589134335517883,\n",
       "  0.2536153793334961,\n",
       "  0.24273839592933655,\n",
       "  0.23256908357143402,\n",
       "  0.22375744581222534,\n",
       "  0.21558202803134918,\n",
       "  0.20786872506141663,\n",
       "  0.20092087984085083,\n",
       "  0.19427257776260376,\n",
       "  0.18803368508815765,\n",
       "  0.18226568400859833,\n",
       "  0.17673516273498535,\n",
       "  0.1713884025812149,\n",
       "  0.166616290807724,\n",
       "  0.16176855564117432,\n",
       "  0.157351553440094,\n",
       "  0.1531589776277542,\n",
       "  0.14920887351036072,\n",
       "  0.14512886106967926,\n",
       "  0.1415550708770752,\n",
       "  0.13799290359020233,\n",
       "  0.1345224231481552,\n",
       "  0.13122500479221344,\n",
       "  0.12834717333316803,\n",
       "  0.1251116544008255,\n",
       "  0.12224740535020828,\n",
       "  0.11943504214286804,\n",
       "  0.116664357483387,\n",
       "  0.11427651345729828,\n",
       "  0.11170760542154312,\n",
       "  0.10896100848913193,\n",
       "  0.10674706101417542,\n",
       "  0.10448850691318512,\n",
       "  0.1023392453789711,\n",
       "  0.10019924491643906,\n",
       "  0.09812351316213608,\n",
       "  0.09615366160869598,\n",
       "  0.09406448900699615,\n",
       "  0.09224370121955872,\n",
       "  0.0903957411646843,\n",
       "  0.08872652053833008,\n",
       "  0.0870792418718338,\n",
       "  0.08531903475522995],\n",
       " 'val_accuracy': [0.868399977684021,\n",
       "  0.8982999920845032,\n",
       "  0.9082000255584717,\n",
       "  0.9154000282287598,\n",
       "  0.9193999767303467,\n",
       "  0.92330002784729,\n",
       "  0.9259999990463257,\n",
       "  0.9287999868392944,\n",
       "  0.9319000244140625,\n",
       "  0.9365000128746033,\n",
       "  0.9380000233650208,\n",
       "  0.9405999779701233,\n",
       "  0.9424999952316284,\n",
       "  0.9445000290870667,\n",
       "  0.9472000002861023,\n",
       "  0.9498000144958496,\n",
       "  0.9485999941825867,\n",
       "  0.9509000182151794,\n",
       "  0.9523000121116638,\n",
       "  0.9531999826431274,\n",
       "  0.9545999765396118,\n",
       "  0.9556999802589417,\n",
       "  0.9564999938011169,\n",
       "  0.9571999907493591,\n",
       "  0.9580000042915344,\n",
       "  0.9585999846458435,\n",
       "  0.958899974822998,\n",
       "  0.9603999853134155,\n",
       "  0.9610999822616577,\n",
       "  0.9613000154495239,\n",
       "  0.9624999761581421,\n",
       "  0.9635000228881836,\n",
       "  0.963699996471405,\n",
       "  0.9639999866485596,\n",
       "  0.9645000100135803,\n",
       "  0.9646999835968018,\n",
       "  0.9657999873161316,\n",
       "  0.9656999707221985,\n",
       "  0.9666000008583069,\n",
       "  0.9668999910354614,\n",
       "  0.9678000211715698,\n",
       "  0.9682999849319458,\n",
       "  0.9682000279426575,\n",
       "  0.968500018119812,\n",
       "  0.9692999720573425,\n",
       "  0.9682999849319458,\n",
       "  0.970300018787384,\n",
       "  0.9697999954223633,\n",
       "  0.9692999720573425,\n",
       "  0.9706000089645386],\n",
       " 'val_loss': [0.5888599157333374,\n",
       "  0.3892429769039154,\n",
       "  0.3318827450275421,\n",
       "  0.3021281063556671,\n",
       "  0.28470584750175476,\n",
       "  0.265531450510025,\n",
       "  0.2522396445274353,\n",
       "  0.24235248565673828,\n",
       "  0.2343684583902359,\n",
       "  0.22290287911891937,\n",
       "  0.2152053415775299,\n",
       "  0.2088613510131836,\n",
       "  0.20080868899822235,\n",
       "  0.196541428565979,\n",
       "  0.1890890896320343,\n",
       "  0.1837470829486847,\n",
       "  0.18052791059017181,\n",
       "  0.17608368396759033,\n",
       "  0.17130811512470245,\n",
       "  0.16759954392910004,\n",
       "  0.16324439644813538,\n",
       "  0.16025976836681366,\n",
       "  0.15624941885471344,\n",
       "  0.15375974774360657,\n",
       "  0.15034975111484528,\n",
       "  0.14849627017974854,\n",
       "  0.14498364925384521,\n",
       "  0.14319108426570892,\n",
       "  0.14013616740703583,\n",
       "  0.1388200968503952,\n",
       "  0.1354348063468933,\n",
       "  0.13273830711841583,\n",
       "  0.1312197744846344,\n",
       "  0.12882675230503082,\n",
       "  0.12772275507450104,\n",
       "  0.12558946013450623,\n",
       "  0.12406770884990692,\n",
       "  0.1230601817369461,\n",
       "  0.12125928699970245,\n",
       "  0.12008217722177505,\n",
       "  0.11774494498968124,\n",
       "  0.11609283089637756,\n",
       "  0.11540334671735764,\n",
       "  0.11347819864749908,\n",
       "  0.11253420263528824,\n",
       "  0.11206192523241043,\n",
       "  0.11016317456960678,\n",
       "  0.10941947996616364,\n",
       "  0.108260877430439,\n",
       "  0.10670865327119827]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.69518</td>\n",
       "      <td>1.253912</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.588860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.87120</td>\n",
       "      <td>0.507687</td>\n",
       "      <td>0.8983</td>\n",
       "      <td>0.389243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.89200</td>\n",
       "      <td>0.394429</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.331883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90256</td>\n",
       "      <td>0.347664</td>\n",
       "      <td>0.9154</td>\n",
       "      <td>0.302128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90960</td>\n",
       "      <td>0.318661</td>\n",
       "      <td>0.9194</td>\n",
       "      <td>0.284706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.91506</td>\n",
       "      <td>0.297788</td>\n",
       "      <td>0.9233</td>\n",
       "      <td>0.265531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.92070</td>\n",
       "      <td>0.280498</td>\n",
       "      <td>0.9260</td>\n",
       "      <td>0.252240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.92440</td>\n",
       "      <td>0.265891</td>\n",
       "      <td>0.9288</td>\n",
       "      <td>0.242352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.92818</td>\n",
       "      <td>0.253615</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>0.234368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.93136</td>\n",
       "      <td>0.242738</td>\n",
       "      <td>0.9365</td>\n",
       "      <td>0.222903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.93450</td>\n",
       "      <td>0.232569</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>0.215205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.93676</td>\n",
       "      <td>0.223757</td>\n",
       "      <td>0.9406</td>\n",
       "      <td>0.208861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.93894</td>\n",
       "      <td>0.215582</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>0.200809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.94096</td>\n",
       "      <td>0.207869</td>\n",
       "      <td>0.9445</td>\n",
       "      <td>0.196541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.94286</td>\n",
       "      <td>0.200921</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.189089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.94478</td>\n",
       "      <td>0.194273</td>\n",
       "      <td>0.9498</td>\n",
       "      <td>0.183747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.94606</td>\n",
       "      <td>0.188034</td>\n",
       "      <td>0.9486</td>\n",
       "      <td>0.180528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.94780</td>\n",
       "      <td>0.182266</td>\n",
       "      <td>0.9509</td>\n",
       "      <td>0.176084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.94868</td>\n",
       "      <td>0.176735</td>\n",
       "      <td>0.9523</td>\n",
       "      <td>0.171308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.95074</td>\n",
       "      <td>0.171388</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>0.167600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.95176</td>\n",
       "      <td>0.166616</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>0.163244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.95308</td>\n",
       "      <td>0.161769</td>\n",
       "      <td>0.9557</td>\n",
       "      <td>0.160260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.95490</td>\n",
       "      <td>0.157352</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.156249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.153159</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>0.153760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.95694</td>\n",
       "      <td>0.149209</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>0.150350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.95830</td>\n",
       "      <td>0.145129</td>\n",
       "      <td>0.9586</td>\n",
       "      <td>0.148496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.95956</td>\n",
       "      <td>0.141555</td>\n",
       "      <td>0.9589</td>\n",
       "      <td>0.144984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.96032</td>\n",
       "      <td>0.137993</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.143191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.96186</td>\n",
       "      <td>0.134522</td>\n",
       "      <td>0.9611</td>\n",
       "      <td>0.140136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.96294</td>\n",
       "      <td>0.131225</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>0.138820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.96324</td>\n",
       "      <td>0.128347</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.135435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.96454</td>\n",
       "      <td>0.125112</td>\n",
       "      <td>0.9635</td>\n",
       "      <td>0.132738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.96540</td>\n",
       "      <td>0.122247</td>\n",
       "      <td>0.9637</td>\n",
       "      <td>0.131220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.96592</td>\n",
       "      <td>0.119435</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.128827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.96742</td>\n",
       "      <td>0.116664</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.127723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.96804</td>\n",
       "      <td>0.114277</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>0.125589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.96844</td>\n",
       "      <td>0.111708</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>0.124068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.96938</td>\n",
       "      <td>0.108961</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.123060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.96978</td>\n",
       "      <td>0.106747</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.121259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.97060</td>\n",
       "      <td>0.104489</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.120082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.97174</td>\n",
       "      <td>0.102339</td>\n",
       "      <td>0.9678</td>\n",
       "      <td>0.117745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.97190</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.116093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.97262</td>\n",
       "      <td>0.098124</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.115403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.97348</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.113478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.97390</td>\n",
       "      <td>0.094064</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.112534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.97466</td>\n",
       "      <td>0.092244</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.112062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.97552</td>\n",
       "      <td>0.090396</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>0.110163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.97556</td>\n",
       "      <td>0.088727</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.109419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.97614</td>\n",
       "      <td>0.087079</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.108261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.97690</td>\n",
       "      <td>0.085319</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.106709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy      loss  val_accuracy  val_loss\n",
       "0    0.69518  1.253912        0.8684  0.588860\n",
       "1    0.87120  0.507687        0.8983  0.389243\n",
       "2    0.89200  0.394429        0.9082  0.331883\n",
       "3    0.90256  0.347664        0.9154  0.302128\n",
       "4    0.90960  0.318661        0.9194  0.284706\n",
       "5    0.91506  0.297788        0.9233  0.265531\n",
       "6    0.92070  0.280498        0.9260  0.252240\n",
       "7    0.92440  0.265891        0.9288  0.242352\n",
       "8    0.92818  0.253615        0.9319  0.234368\n",
       "9    0.93136  0.242738        0.9365  0.222903\n",
       "10   0.93450  0.232569        0.9380  0.215205\n",
       "11   0.93676  0.223757        0.9406  0.208861\n",
       "12   0.93894  0.215582        0.9425  0.200809\n",
       "13   0.94096  0.207869        0.9445  0.196541\n",
       "14   0.94286  0.200921        0.9472  0.189089\n",
       "15   0.94478  0.194273        0.9498  0.183747\n",
       "16   0.94606  0.188034        0.9486  0.180528\n",
       "17   0.94780  0.182266        0.9509  0.176084\n",
       "18   0.94868  0.176735        0.9523  0.171308\n",
       "19   0.95074  0.171388        0.9532  0.167600\n",
       "20   0.95176  0.166616        0.9546  0.163244\n",
       "21   0.95308  0.161769        0.9557  0.160260\n",
       "22   0.95490  0.157352        0.9565  0.156249\n",
       "23   0.95584  0.153159        0.9572  0.153760\n",
       "24   0.95694  0.149209        0.9580  0.150350\n",
       "25   0.95830  0.145129        0.9586  0.148496\n",
       "26   0.95956  0.141555        0.9589  0.144984\n",
       "27   0.96032  0.137993        0.9604  0.143191\n",
       "28   0.96186  0.134522        0.9611  0.140136\n",
       "29   0.96294  0.131225        0.9613  0.138820\n",
       "30   0.96324  0.128347        0.9625  0.135435\n",
       "31   0.96454  0.125112        0.9635  0.132738\n",
       "32   0.96540  0.122247        0.9637  0.131220\n",
       "33   0.96592  0.119435        0.9640  0.128827\n",
       "34   0.96742  0.116664        0.9645  0.127723\n",
       "35   0.96804  0.114277        0.9647  0.125589\n",
       "36   0.96844  0.111708        0.9658  0.124068\n",
       "37   0.96938  0.108961        0.9657  0.123060\n",
       "38   0.96978  0.106747        0.9666  0.121259\n",
       "39   0.97060  0.104489        0.9669  0.120082\n",
       "40   0.97174  0.102339        0.9678  0.117745\n",
       "41   0.97190  0.100199        0.9683  0.116093\n",
       "42   0.97262  0.098124        0.9682  0.115403\n",
       "43   0.97348  0.096154        0.9685  0.113478\n",
       "44   0.97390  0.094064        0.9693  0.112534\n",
       "45   0.97466  0.092244        0.9683  0.112062\n",
       "46   0.97552  0.090396        0.9703  0.110163\n",
       "47   0.97556  0.088727        0.9698  0.109419\n",
       "48   0.97614  0.087079        0.9693  0.108261\n",
       "49   0.97690  0.085319        0.9706  0.106709"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  5/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9845 - loss: 0.0490 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9661 - loss: 0.1045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09077098965644836, 0.9714000225067139]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yporq\\AppData\\Local\\Temp\\ipykernel_28740\\1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.001, 0.   , 0.   , 0.   , 0.999, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yporq\\AppData\\Local\\Temp\\ipykernel_28740\\1084033691.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.any(np.isnan(X_train)))\n",
    "print(np.any(np.isnan(X_valid)))\n",
    "print(np.any(np.isnan(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 2.3250 - val_loss: 0.5995\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.5561 - val_loss: 0.5368\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.4697 - val_loss: 0.4969\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.4612 - val_loss: 0.4808\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.4392 - val_loss: 0.4647\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.4751 - val_loss: 0.4571\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.4556 - val_loss: 0.4488\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.4282 - val_loss: 0.4424\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.4201 - val_loss: 0.4384\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.4282 - val_loss: 0.4333\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.4215 - val_loss: 0.4294\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.4093 - val_loss: 0.4247\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.3991 - val_loss: 0.4191\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.4037 - val_loss: 0.4217\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.3938 - val_loss: 0.4161\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.3852 - val_loss: 0.4127\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.4106 - val_loss: 0.4090\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.3992 - val_loss: 0.4054\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.3738 - val_loss: 0.4068\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.3846 - val_loss: 0.4019\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.SGD(clipnorm=1)\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = optimizer) # con optimizer = \"sgd\" aparece la explosión del gradiente y nan's \n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">303</span> (1.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m303\u001b[0m (1.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4328\n",
      "0.40249305963516235\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.0493264],\n",
       "       [1.569633 ],\n",
       "       [2.379537 ],\n",
       "       [1.1617668],\n",
       "       [1.036141 ]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown variable: <Variable path=sequential_2/dense_6/kernel, shape=(8, 30), dtype=float32, value=[[ 0.2681044  -0.28205648 -0.23864846  0.05171523  0.05145674 -0.3223664\n   0.38954902  0.03231357 -0.0198546  -0.30648997  0.23063505 -0.03053145\n   0.41255346  0.19709416 -0.07308101  0.29738352  0.08097778  0.10838547\n  -0.1977933  -0.19006512 -0.06450176 -0.24609287  0.41619512 -0.01096848\n  -0.2717117   0.31605172  0.00168225  0.39598453 -0.33767682 -0.02351377]\n [ 0.20023197  0.23331244 -0.21550605  0.13911615 -0.01221084  0.07195243\n   0.11137844  0.2511988   0.11452582 -0.01839179  0.1188498   0.40411624\n   0.17335689 -0.13923675  0.04071337  0.02608039  0.27386513  0.188024\n  -0.17342313  0.12180758  0.33019388 -0.0250597   0.14494793 -0.03196403\n   0.03101935  0.2751853   0.05362247  0.21536465  0.36458755 -0.41684115]\n [ 0.164317    0.11693785 -0.00616004 -0.19429532 -0.371085    0.24790886\n  -0.11934169  0.10681892 -0.19480003  0.00691058 -0.10842312 -0.25065082\n   0.4986561   0.27693495  0.3318396  -0.0764066   0.15316722 -0.05607016\n   0.15750928 -0.22656882  0.09814528  0.03989666 -0.24366619  0.0247677\n   0.20179197  0.01625914  0.10241492 -0.29528213 -0.21615846  0.25494182]\n [ 0.16996503 -0.3489319   0.38135326  0.03178542  0.23195529  0.31125763\n   0.5682292   0.21440123  0.1329327   0.26441592  0.14310697 -0.27082005\n   0.18370804 -0.01044997 -0.21876459 -0.1538061  -0.00775924 -0.14612427\n   0.18862532  0.0014644   0.04923252 -0.18970363  0.33574858  0.24836513\n  -0.5657434   0.15543829 -0.2361507   0.3160549  -0.263132    0.01398456]\n [ 0.29455328  0.2799721  -0.27569258  0.05844821 -0.02726305 -0.11502279\n  -0.20638809  0.21814346 -0.14274113  0.23274696 -0.22748178  0.3774051\n  -0.0964696   0.33776897 -0.39771476  0.36690506 -0.09807055  0.06716737\n   0.27803123  0.0391973   0.14903396  0.09116471  0.01581404 -0.03909305\n   0.13229722 -0.11807372 -0.02135273  0.2706869  -0.20883164  0.1965523 ]\n [ 0.18793155  0.250866   -0.20325239  0.16226646 -0.99121135 -0.00314459\n   0.01452298  0.2158527   0.3718778  -0.3284612  -0.6401925   0.01993535\n  -0.00252101  0.21673088 -0.06166964  0.05426893 -0.01576128 -0.43516788\n  -0.3335468  -0.39397427 -0.08614705 -0.32514974 -0.7212471  -0.7189503\n   0.12257216 -0.13804412 -0.35854313 -0.67044693  0.10401196 -0.29255062]\n [-0.07210447 -0.04339778  0.04370572 -0.44664526 -0.5008547   0.36109138\n   0.15683746 -0.35827982  0.0807016   0.07713044  0.22451536  0.2450608\n  -0.6461425  -0.03278198 -0.0642444   0.20523041 -0.21980207 -0.16875896\n  -0.19567743  0.12658505  0.382719    0.4291038  -0.27707884 -0.13746065\n  -0.08602532 -0.300496   -0.50588715 -0.46235812  0.3147714  -0.03140869]\n [ 0.11899587  0.33831778 -0.22779578  0.2034314  -0.47809047  0.22379176\n   0.01854334  0.23646495 -0.25172585 -0.3810466   0.05356371  0.21348697\n  -0.4498831  -0.1818622   0.20886806 -0.04052321  0.19242468 -0.28601974\n  -0.30465874  0.19917254 -0.01217086  0.02914548 -0.26891297 -0.40501052\n   0.32668078  0.35528186 -0.01344098 -0.3643916  -0.04198464 -0.26160112]]>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m checkpoint_cb \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:329\u001b[0m, in \u001b[0;36mBaseOptimizer._check_variables_are_known\u001b[1;34m(self, variables)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_key(v) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables_indices:\n\u001b[1;32m--> 329\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    330\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This optimizer can only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe called for the variables it was originally built with. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen working with a new set of variables, you should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecreate a new optimizer instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown variable: <Variable path=sequential_2/dense_6/kernel, shape=(8, 30), dtype=float32, value=[[ 0.2681044  -0.28205648 -0.23864846  0.05171523  0.05145674 -0.3223664\n   0.38954902  0.03231357 -0.0198546  -0.30648997  0.23063505 -0.03053145\n   0.41255346  0.19709416 -0.07308101  0.29738352  0.08097778  0.10838547\n  -0.1977933  -0.19006512 -0.06450176 -0.24609287  0.41619512 -0.01096848\n  -0.2717117   0.31605172  0.00168225  0.39598453 -0.33767682 -0.02351377]\n [ 0.20023197  0.23331244 -0.21550605  0.13911615 -0.01221084  0.07195243\n   0.11137844  0.2511988   0.11452582 -0.01839179  0.1188498   0.40411624\n   0.17335689 -0.13923675  0.04071337  0.02608039  0.27386513  0.188024\n  -0.17342313  0.12180758  0.33019388 -0.0250597   0.14494793 -0.03196403\n   0.03101935  0.2751853   0.05362247  0.21536465  0.36458755 -0.41684115]\n [ 0.164317    0.11693785 -0.00616004 -0.19429532 -0.371085    0.24790886\n  -0.11934169  0.10681892 -0.19480003  0.00691058 -0.10842312 -0.25065082\n   0.4986561   0.27693495  0.3318396  -0.0764066   0.15316722 -0.05607016\n   0.15750928 -0.22656882  0.09814528  0.03989666 -0.24366619  0.0247677\n   0.20179197  0.01625914  0.10241492 -0.29528213 -0.21615846  0.25494182]\n [ 0.16996503 -0.3489319   0.38135326  0.03178542  0.23195529  0.31125763\n   0.5682292   0.21440123  0.1329327   0.26441592  0.14310697 -0.27082005\n   0.18370804 -0.01044997 -0.21876459 -0.1538061  -0.00775924 -0.14612427\n   0.18862532  0.0014644   0.04923252 -0.18970363  0.33574858  0.24836513\n  -0.5657434   0.15543829 -0.2361507   0.3160549  -0.263132    0.01398456]\n [ 0.29455328  0.2799721  -0.27569258  0.05844821 -0.02726305 -0.11502279\n  -0.20638809  0.21814346 -0.14274113  0.23274696 -0.22748178  0.3774051\n  -0.0964696   0.33776897 -0.39771476  0.36690506 -0.09807055  0.06716737\n   0.27803123  0.0391973   0.14903396  0.09116471  0.01581404 -0.03909305\n   0.13229722 -0.11807372 -0.02135273  0.2706869  -0.20883164  0.1965523 ]\n [ 0.18793155  0.250866   -0.20325239  0.16226646 -0.99121135 -0.00314459\n   0.01452298  0.2158527   0.3718778  -0.3284612  -0.6401925   0.01993535\n  -0.00252101  0.21673088 -0.06166964  0.05426893 -0.01576128 -0.43516788\n  -0.3335468  -0.39397427 -0.08614705 -0.32514974 -0.7212471  -0.7189503\n   0.12257216 -0.13804412 -0.35854313 -0.67044693  0.10401196 -0.29255062]\n [-0.07210447 -0.04339778  0.04370572 -0.44664526 -0.5008547   0.36109138\n   0.15683746 -0.35827982  0.0807016   0.07713044  0.22451536  0.2450608\n  -0.6461425  -0.03278198 -0.0642444   0.20523041 -0.21980207 -0.16875896\n  -0.19567743  0.12658505  0.382719    0.4291038  -0.27707884 -0.13746065\n  -0.08602532 -0.300496   -0.50588715 -0.46235812  0.3147714  -0.03140869]\n [ 0.11899587  0.33831778 -0.22779578  0.2034314  -0.47809047  0.22379176\n   0.01854334  0.23646495 -0.25172585 -0.3810466   0.05356371  0.21348697\n  -0.4498831  -0.1818622   0.20886806 -0.04052321  0.19242468 -0.28601974\n  -0.30465874  0.19917254 -0.01217086  0.02914548 -0.26891297 -0.40501052\n   0.32668078  0.35528186 -0.01344098 -0.3643916  -0.04198464 -0.26160112]]>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance."
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3366 - val_loss: 0.3556\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3356 - val_loss: 0.3625\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3352 - val_loss: 0.3562\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3349 - val_loss: 0.3583\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3341 - val_loss: 0.3520\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3328 - val_loss: 0.3556\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.3512\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.3579\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3324 - val_loss: 0.3559\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3309 - val_loss: 0.3505\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3303 - val_loss: 0.3482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3288 - val_loss: 0.3528\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3286 - val_loss: 0.3525\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3284 - val_loss: 0.3479\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3276 - val_loss: 0.3523\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3276 - val_loss: 0.3486\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3271 - val_loss: 0.3461\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3262 - val_loss: 0.3519\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3262 - val_loss: 0.3521\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3256 - val_loss: 0.3547\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=20,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

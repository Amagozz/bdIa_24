{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.47.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: keras in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.9.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow --user\n",
    "#!pip install keras --user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 11:14:08.059227: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zl/x4wcpc6n7p75fkkmssl2_0vh0000gn/T/ipykernel_26144/3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Flatten name=flatten_1, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*28*28 + 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5603 - loss: 1.6804 - val_accuracy: 0.8680 - val_loss: 0.5791\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8650 - loss: 0.5475 - val_accuracy: 0.9002 - val_loss: 0.3876\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8904 - loss: 0.4059 - val_accuracy: 0.9113 - val_loss: 0.3311\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9030 - loss: 0.3507 - val_accuracy: 0.9171 - val_loss: 0.3030\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9107 - loss: 0.3224 - val_accuracy: 0.9215 - val_loss: 0.2825\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9153 - loss: 0.3008 - val_accuracy: 0.9264 - val_loss: 0.2648\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9219 - loss: 0.2828 - val_accuracy: 0.9301 - val_loss: 0.2537\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9246 - loss: 0.2687 - val_accuracy: 0.9337 - val_loss: 0.2418\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9278 - loss: 0.2512 - val_accuracy: 0.9340 - val_loss: 0.2347\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9314 - loss: 0.2384 - val_accuracy: 0.9390 - val_loss: 0.2239\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9349 - loss: 0.2333 - val_accuracy: 0.9407 - val_loss: 0.2156\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9364 - loss: 0.2261 - val_accuracy: 0.9426 - val_loss: 0.2104\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9407 - loss: 0.2059 - val_accuracy: 0.9446 - val_loss: 0.2028\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9399 - loss: 0.2072 - val_accuracy: 0.9469 - val_loss: 0.1957\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9440 - loss: 0.1983 - val_accuracy: 0.9490 - val_loss: 0.1906\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9460 - loss: 0.1891 - val_accuracy: 0.9490 - val_loss: 0.1854\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9471 - loss: 0.1869 - val_accuracy: 0.9514 - val_loss: 0.1792\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9501 - loss: 0.1806 - val_accuracy: 0.9540 - val_loss: 0.1758\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9488 - loss: 0.1785 - val_accuracy: 0.9537 - val_loss: 0.1714\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9518 - loss: 0.1684 - val_accuracy: 0.9546 - val_loss: 0.1668\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9547 - loss: 0.1621 - val_accuracy: 0.9554 - val_loss: 0.1638\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9560 - loss: 0.1540 - val_accuracy: 0.9572 - val_loss: 0.1586\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9545 - loss: 0.1554 - val_accuracy: 0.9582 - val_loss: 0.1556\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9571 - loss: 0.1504 - val_accuracy: 0.9592 - val_loss: 0.1534\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9590 - loss: 0.1431 - val_accuracy: 0.9594 - val_loss: 0.1494\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9589 - loss: 0.1418 - val_accuracy: 0.9604 - val_loss: 0.1473\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9616 - loss: 0.1376 - val_accuracy: 0.9614 - val_loss: 0.1441\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9607 - loss: 0.1339 - val_accuracy: 0.9606 - val_loss: 0.1433\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9627 - loss: 0.1302 - val_accuracy: 0.9630 - val_loss: 0.1387\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9653 - loss: 0.1243 - val_accuracy: 0.9632 - val_loss: 0.1386\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9662 - loss: 0.1198 - val_accuracy: 0.9648 - val_loss: 0.1339\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9653 - loss: 0.1193 - val_accuracy: 0.9640 - val_loss: 0.1331\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.1164 - val_accuracy: 0.9637 - val_loss: 0.1307\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9675 - loss: 0.1156 - val_accuracy: 0.9653 - val_loss: 0.1284\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9680 - loss: 0.1103 - val_accuracy: 0.9664 - val_loss: 0.1269\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9699 - loss: 0.1072 - val_accuracy: 0.9668 - val_loss: 0.1247\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.1098 - val_accuracy: 0.9668 - val_loss: 0.1240\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9709 - loss: 0.1045 - val_accuracy: 0.9673 - val_loss: 0.1221\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9720 - loss: 0.1011 - val_accuracy: 0.9677 - val_loss: 0.1194\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9704 - loss: 0.1015 - val_accuracy: 0.9681 - val_loss: 0.1189\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9717 - loss: 0.1002 - val_accuracy: 0.9676 - val_loss: 0.1182\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9730 - loss: 0.0983 - val_accuracy: 0.9680 - val_loss: 0.1171\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9759 - loss: 0.0901 - val_accuracy: 0.9693 - val_loss: 0.1144\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9732 - loss: 0.0935 - val_accuracy: 0.9692 - val_loss: 0.1133\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9749 - loss: 0.0890 - val_accuracy: 0.9699 - val_loss: 0.1131\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9754 - loss: 0.0890 - val_accuracy: 0.9699 - val_loss: 0.1114\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9754 - loss: 0.0890 - val_accuracy: 0.9704 - val_loss: 0.1102\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9782 - loss: 0.0844 - val_accuracy: 0.9709 - val_loss: 0.1092\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9770 - loss: 0.0852 - val_accuracy: 0.9701 - val_loss: 0.1102\n",
      "Epoch 50/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9765 - loss: 0.0824 - val_accuracy: 0.9700 - val_loss: 0.1074\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0814 - val_accuracy: 0.9703 - val_loss: 0.1057\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9786 - loss: 0.0779 - val_accuracy: 0.9699 - val_loss: 0.1045\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9794 - loss: 0.0786 - val_accuracy: 0.9715 - val_loss: 0.1014\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9793 - loss: 0.0759 - val_accuracy: 0.9724 - val_loss: 0.1006\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9803 - loss: 0.0707 - val_accuracy: 0.9720 - val_loss: 0.0999\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9809 - loss: 0.0682 - val_accuracy: 0.9720 - val_loss: 0.0974\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.0635 - val_accuracy: 0.9723 - val_loss: 0.1011\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9835 - loss: 0.0627 - val_accuracy: 0.9736 - val_loss: 0.0964\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9839 - loss: 0.0602 - val_accuracy: 0.9730 - val_loss: 0.0957\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.0589 - val_accuracy: 0.9737 - val_loss: 0.0932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16642e350>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 'auto', 'epochs': 50, 'steps': 391}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.7229800224304199,\n",
       "  0.8737599849700928,\n",
       "  0.8940600156784058,\n",
       "  0.9048200249671936,\n",
       "  0.9116799831390381,\n",
       "  0.9164400100708008,\n",
       "  0.9220600128173828,\n",
       "  0.9255200028419495,\n",
       "  0.9282400012016296,\n",
       "  0.9319199919700623,\n",
       "  0.9348800182342529,\n",
       "  0.9380599856376648,\n",
       "  0.9395400285720825,\n",
       "  0.9416400194168091,\n",
       "  0.9442800283432007,\n",
       "  0.9458000063896179,\n",
       "  0.9474400281906128,\n",
       "  0.9488999843597412,\n",
       "  0.9503600001335144,\n",
       "  0.9521600008010864,\n",
       "  0.9533200263977051,\n",
       "  0.9549400210380554,\n",
       "  0.9561799764633179,\n",
       "  0.9574199914932251,\n",
       "  0.9583799839019775,\n",
       "  0.9597799777984619,\n",
       "  0.9609400033950806,\n",
       "  0.9617599844932556,\n",
       "  0.9628400206565857,\n",
       "  0.9641199707984924,\n",
       "  0.9646999835968018,\n",
       "  0.965719997882843,\n",
       "  0.9666600227355957,\n",
       "  0.9672399759292603,\n",
       "  0.9679200053215027,\n",
       "  0.9692000150680542,\n",
       "  0.969980001449585,\n",
       "  0.9706400036811829,\n",
       "  0.9714800119400024,\n",
       "  0.971560001373291,\n",
       "  0.9722800254821777,\n",
       "  0.9735000133514404,\n",
       "  0.9738799929618835,\n",
       "  0.9739800095558167,\n",
       "  0.9747400283813477,\n",
       "  0.9755399823188782,\n",
       "  0.9759399890899658,\n",
       "  0.9767400026321411,\n",
       "  0.9766600131988525,\n",
       "  0.9774199724197388],\n",
       " 'loss': [1.2092669010162354,\n",
       "  0.5011366009712219,\n",
       "  0.39083200693130493,\n",
       "  0.34432199597358704,\n",
       "  0.31595948338508606,\n",
       "  0.29482999444007874,\n",
       "  0.27789121866226196,\n",
       "  0.2639380991458893,\n",
       "  0.25135114789009094,\n",
       "  0.24011974036693573,\n",
       "  0.2301766723394394,\n",
       "  0.22089777886867523,\n",
       "  0.21255673468112946,\n",
       "  0.2047479897737503,\n",
       "  0.19745968282222748,\n",
       "  0.19056840240955353,\n",
       "  0.18436987698078156,\n",
       "  0.1782539039850235,\n",
       "  0.1727275401353836,\n",
       "  0.1671810895204544,\n",
       "  0.16229230165481567,\n",
       "  0.15770049393177032,\n",
       "  0.15300866961479187,\n",
       "  0.14877991378307343,\n",
       "  0.1447957307100296,\n",
       "  0.1409509927034378,\n",
       "  0.1372465044260025,\n",
       "  0.13354572653770447,\n",
       "  0.130197212100029,\n",
       "  0.12708613276481628,\n",
       "  0.1238793134689331,\n",
       "  0.12085770815610886,\n",
       "  0.11816023290157318,\n",
       "  0.11535406857728958,\n",
       "  0.11272011697292328,\n",
       "  0.11001287400722504,\n",
       "  0.10760602355003357,\n",
       "  0.10530039668083191,\n",
       "  0.10303862392902374,\n",
       "  0.10088246315717697,\n",
       "  0.09869120270013809,\n",
       "  0.09661227464675903,\n",
       "  0.09455852210521698,\n",
       "  0.09268750995397568,\n",
       "  0.09072428941726685,\n",
       "  0.08899296820163727,\n",
       "  0.08730517327785492,\n",
       "  0.08548901230096817,\n",
       "  0.08391939103603363,\n",
       "  0.08220341801643372],\n",
       " 'val_accuracy': [0.8679999709129333,\n",
       "  0.9002000093460083,\n",
       "  0.911300003528595,\n",
       "  0.9171000123023987,\n",
       "  0.921500027179718,\n",
       "  0.9264000058174133,\n",
       "  0.9301000237464905,\n",
       "  0.9337000250816345,\n",
       "  0.9340000152587891,\n",
       "  0.9390000104904175,\n",
       "  0.9406999945640564,\n",
       "  0.9426000118255615,\n",
       "  0.944599986076355,\n",
       "  0.9469000101089478,\n",
       "  0.9490000009536743,\n",
       "  0.9490000009536743,\n",
       "  0.9513999819755554,\n",
       "  0.9539999961853027,\n",
       "  0.9537000060081482,\n",
       "  0.9545999765396118,\n",
       "  0.9553999900817871,\n",
       "  0.9571999907493591,\n",
       "  0.9581999778747559,\n",
       "  0.9592000246047974,\n",
       "  0.9593999981880188,\n",
       "  0.9603999853134155,\n",
       "  0.9613999724388123,\n",
       "  0.9606000185012817,\n",
       "  0.9629999995231628,\n",
       "  0.9631999731063843,\n",
       "  0.9648000001907349,\n",
       "  0.9639999866485596,\n",
       "  0.963699996471405,\n",
       "  0.9653000235557556,\n",
       "  0.9664000272750854,\n",
       "  0.9667999744415283,\n",
       "  0.9667999744415283,\n",
       "  0.9672999978065491,\n",
       "  0.9677000045776367,\n",
       "  0.9681000113487244,\n",
       "  0.9675999879837036,\n",
       "  0.9679999947547913,\n",
       "  0.9692999720573425,\n",
       "  0.9692000150680542,\n",
       "  0.9699000120162964,\n",
       "  0.9699000120162964,\n",
       "  0.9703999757766724,\n",
       "  0.9708999991416931,\n",
       "  0.9700999855995178,\n",
       "  0.9700000286102295],\n",
       " 'val_loss': [0.5791327357292175,\n",
       "  0.3876015543937683,\n",
       "  0.33105096220970154,\n",
       "  0.3030451834201813,\n",
       "  0.282546728849411,\n",
       "  0.26475220918655396,\n",
       "  0.25370100140571594,\n",
       "  0.24176514148712158,\n",
       "  0.23473286628723145,\n",
       "  0.22385668754577637,\n",
       "  0.21562106907367706,\n",
       "  0.21035410463809967,\n",
       "  0.20278064906597137,\n",
       "  0.19574454426765442,\n",
       "  0.19061243534088135,\n",
       "  0.1853981763124466,\n",
       "  0.17916947603225708,\n",
       "  0.17580831050872803,\n",
       "  0.17137397825717926,\n",
       "  0.16680587828159332,\n",
       "  0.16383682191371918,\n",
       "  0.15856865048408508,\n",
       "  0.15558166801929474,\n",
       "  0.15343116223812103,\n",
       "  0.1493898183107376,\n",
       "  0.14734181761741638,\n",
       "  0.14409494400024414,\n",
       "  0.14328323304653168,\n",
       "  0.13868573307991028,\n",
       "  0.13859349489212036,\n",
       "  0.13394533097743988,\n",
       "  0.13309155404567719,\n",
       "  0.1306917667388916,\n",
       "  0.12835925817489624,\n",
       "  0.1268778145313263,\n",
       "  0.12470389157533646,\n",
       "  0.12401274591684341,\n",
       "  0.12208949029445648,\n",
       "  0.11943817138671875,\n",
       "  0.11885246634483337,\n",
       "  0.11816608905792236,\n",
       "  0.11712653934955597,\n",
       "  0.11438644677400589,\n",
       "  0.11331690847873688,\n",
       "  0.1130535751581192,\n",
       "  0.11144916713237762,\n",
       "  0.11022652685642242,\n",
       "  0.10922151058912277,\n",
       "  0.11021573841571808,\n",
       "  0.10735970735549927]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.7229800224304199,\n",
       "  0.8737599849700928,\n",
       "  0.8940600156784058,\n",
       "  0.9048200249671936,\n",
       "  0.9116799831390381,\n",
       "  0.9164400100708008,\n",
       "  0.9220600128173828,\n",
       "  0.9255200028419495,\n",
       "  0.9282400012016296,\n",
       "  0.9319199919700623,\n",
       "  0.9348800182342529,\n",
       "  0.9380599856376648,\n",
       "  0.9395400285720825,\n",
       "  0.9416400194168091,\n",
       "  0.9442800283432007,\n",
       "  0.9458000063896179,\n",
       "  0.9474400281906128,\n",
       "  0.9488999843597412,\n",
       "  0.9503600001335144,\n",
       "  0.9521600008010864,\n",
       "  0.9533200263977051,\n",
       "  0.9549400210380554,\n",
       "  0.9561799764633179,\n",
       "  0.9574199914932251,\n",
       "  0.9583799839019775,\n",
       "  0.9597799777984619,\n",
       "  0.9609400033950806,\n",
       "  0.9617599844932556,\n",
       "  0.9628400206565857,\n",
       "  0.9641199707984924,\n",
       "  0.9646999835968018,\n",
       "  0.965719997882843,\n",
       "  0.9666600227355957,\n",
       "  0.9672399759292603,\n",
       "  0.9679200053215027,\n",
       "  0.9692000150680542,\n",
       "  0.969980001449585,\n",
       "  0.9706400036811829,\n",
       "  0.9714800119400024,\n",
       "  0.971560001373291,\n",
       "  0.9722800254821777,\n",
       "  0.9735000133514404,\n",
       "  0.9738799929618835,\n",
       "  0.9739800095558167,\n",
       "  0.9747400283813477,\n",
       "  0.9755399823188782,\n",
       "  0.9759399890899658,\n",
       "  0.9767400026321411,\n",
       "  0.9766600131988525,\n",
       "  0.9774199724197388],\n",
       " 'loss': [1.2092669010162354,\n",
       "  0.5011366009712219,\n",
       "  0.39083200693130493,\n",
       "  0.34432199597358704,\n",
       "  0.31595948338508606,\n",
       "  0.29482999444007874,\n",
       "  0.27789121866226196,\n",
       "  0.2639380991458893,\n",
       "  0.25135114789009094,\n",
       "  0.24011974036693573,\n",
       "  0.2301766723394394,\n",
       "  0.22089777886867523,\n",
       "  0.21255673468112946,\n",
       "  0.2047479897737503,\n",
       "  0.19745968282222748,\n",
       "  0.19056840240955353,\n",
       "  0.18436987698078156,\n",
       "  0.1782539039850235,\n",
       "  0.1727275401353836,\n",
       "  0.1671810895204544,\n",
       "  0.16229230165481567,\n",
       "  0.15770049393177032,\n",
       "  0.15300866961479187,\n",
       "  0.14877991378307343,\n",
       "  0.1447957307100296,\n",
       "  0.1409509927034378,\n",
       "  0.1372465044260025,\n",
       "  0.13354572653770447,\n",
       "  0.130197212100029,\n",
       "  0.12708613276481628,\n",
       "  0.1238793134689331,\n",
       "  0.12085770815610886,\n",
       "  0.11816023290157318,\n",
       "  0.11535406857728958,\n",
       "  0.11272011697292328,\n",
       "  0.11001287400722504,\n",
       "  0.10760602355003357,\n",
       "  0.10530039668083191,\n",
       "  0.10303862392902374,\n",
       "  0.10088246315717697,\n",
       "  0.09869120270013809,\n",
       "  0.09661227464675903,\n",
       "  0.09455852210521698,\n",
       "  0.09268750995397568,\n",
       "  0.09072428941726685,\n",
       "  0.08899296820163727,\n",
       "  0.08730517327785492,\n",
       "  0.08548901230096817,\n",
       "  0.08391939103603363,\n",
       "  0.08220341801643372],\n",
       " 'val_accuracy': [0.8679999709129333,\n",
       "  0.9002000093460083,\n",
       "  0.911300003528595,\n",
       "  0.9171000123023987,\n",
       "  0.921500027179718,\n",
       "  0.9264000058174133,\n",
       "  0.9301000237464905,\n",
       "  0.9337000250816345,\n",
       "  0.9340000152587891,\n",
       "  0.9390000104904175,\n",
       "  0.9406999945640564,\n",
       "  0.9426000118255615,\n",
       "  0.944599986076355,\n",
       "  0.9469000101089478,\n",
       "  0.9490000009536743,\n",
       "  0.9490000009536743,\n",
       "  0.9513999819755554,\n",
       "  0.9539999961853027,\n",
       "  0.9537000060081482,\n",
       "  0.9545999765396118,\n",
       "  0.9553999900817871,\n",
       "  0.9571999907493591,\n",
       "  0.9581999778747559,\n",
       "  0.9592000246047974,\n",
       "  0.9593999981880188,\n",
       "  0.9603999853134155,\n",
       "  0.9613999724388123,\n",
       "  0.9606000185012817,\n",
       "  0.9629999995231628,\n",
       "  0.9631999731063843,\n",
       "  0.9648000001907349,\n",
       "  0.9639999866485596,\n",
       "  0.963699996471405,\n",
       "  0.9653000235557556,\n",
       "  0.9664000272750854,\n",
       "  0.9667999744415283,\n",
       "  0.9667999744415283,\n",
       "  0.9672999978065491,\n",
       "  0.9677000045776367,\n",
       "  0.9681000113487244,\n",
       "  0.9675999879837036,\n",
       "  0.9679999947547913,\n",
       "  0.9692999720573425,\n",
       "  0.9692000150680542,\n",
       "  0.9699000120162964,\n",
       "  0.9699000120162964,\n",
       "  0.9703999757766724,\n",
       "  0.9708999991416931,\n",
       "  0.9700999855995178,\n",
       "  0.9700000286102295],\n",
       " 'val_loss': [0.5791327357292175,\n",
       "  0.3876015543937683,\n",
       "  0.33105096220970154,\n",
       "  0.3030451834201813,\n",
       "  0.282546728849411,\n",
       "  0.26475220918655396,\n",
       "  0.25370100140571594,\n",
       "  0.24176514148712158,\n",
       "  0.23473286628723145,\n",
       "  0.22385668754577637,\n",
       "  0.21562106907367706,\n",
       "  0.21035410463809967,\n",
       "  0.20278064906597137,\n",
       "  0.19574454426765442,\n",
       "  0.19061243534088135,\n",
       "  0.1853981763124466,\n",
       "  0.17916947603225708,\n",
       "  0.17580831050872803,\n",
       "  0.17137397825717926,\n",
       "  0.16680587828159332,\n",
       "  0.16383682191371918,\n",
       "  0.15856865048408508,\n",
       "  0.15558166801929474,\n",
       "  0.15343116223812103,\n",
       "  0.1493898183107376,\n",
       "  0.14734181761741638,\n",
       "  0.14409494400024414,\n",
       "  0.14328323304653168,\n",
       "  0.13868573307991028,\n",
       "  0.13859349489212036,\n",
       "  0.13394533097743988,\n",
       "  0.13309155404567719,\n",
       "  0.1306917667388916,\n",
       "  0.12835925817489624,\n",
       "  0.1268778145313263,\n",
       "  0.12470389157533646,\n",
       "  0.12401274591684341,\n",
       "  0.12208949029445648,\n",
       "  0.11943817138671875,\n",
       "  0.11885246634483337,\n",
       "  0.11816608905792236,\n",
       "  0.11712653934955597,\n",
       "  0.11438644677400589,\n",
       "  0.11331690847873688,\n",
       "  0.1130535751581192,\n",
       "  0.11144916713237762,\n",
       "  0.11022652685642242,\n",
       "  0.10922151058912277,\n",
       "  0.11021573841571808,\n",
       "  0.10735970735549927]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.72298</td>\n",
       "      <td>1.209267</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.579133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.87376</td>\n",
       "      <td>0.501137</td>\n",
       "      <td>0.9002</td>\n",
       "      <td>0.387602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.89406</td>\n",
       "      <td>0.390832</td>\n",
       "      <td>0.9113</td>\n",
       "      <td>0.331051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90482</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.9171</td>\n",
       "      <td>0.303045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.91168</td>\n",
       "      <td>0.315959</td>\n",
       "      <td>0.9215</td>\n",
       "      <td>0.282547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.91644</td>\n",
       "      <td>0.294830</td>\n",
       "      <td>0.9264</td>\n",
       "      <td>0.264752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.92206</td>\n",
       "      <td>0.277891</td>\n",
       "      <td>0.9301</td>\n",
       "      <td>0.253701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.92552</td>\n",
       "      <td>0.263938</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>0.241765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.92824</td>\n",
       "      <td>0.251351</td>\n",
       "      <td>0.9340</td>\n",
       "      <td>0.234733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.93192</td>\n",
       "      <td>0.240120</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.223857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.93488</td>\n",
       "      <td>0.230177</td>\n",
       "      <td>0.9407</td>\n",
       "      <td>0.215621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.93806</td>\n",
       "      <td>0.220898</td>\n",
       "      <td>0.9426</td>\n",
       "      <td>0.210354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.93954</td>\n",
       "      <td>0.212557</td>\n",
       "      <td>0.9446</td>\n",
       "      <td>0.202781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.94164</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.9469</td>\n",
       "      <td>0.195745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.94428</td>\n",
       "      <td>0.197460</td>\n",
       "      <td>0.9490</td>\n",
       "      <td>0.190612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.94580</td>\n",
       "      <td>0.190568</td>\n",
       "      <td>0.9490</td>\n",
       "      <td>0.185398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.94744</td>\n",
       "      <td>0.184370</td>\n",
       "      <td>0.9514</td>\n",
       "      <td>0.179169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.94890</td>\n",
       "      <td>0.178254</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.175808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.95036</td>\n",
       "      <td>0.172728</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.171374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.95216</td>\n",
       "      <td>0.167181</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>0.166806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.95332</td>\n",
       "      <td>0.162292</td>\n",
       "      <td>0.9554</td>\n",
       "      <td>0.163837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.95494</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>0.158569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.95618</td>\n",
       "      <td>0.153009</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.155582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.95742</td>\n",
       "      <td>0.148780</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.153431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.95838</td>\n",
       "      <td>0.144796</td>\n",
       "      <td>0.9594</td>\n",
       "      <td>0.149390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.95978</td>\n",
       "      <td>0.140951</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.147342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.96094</td>\n",
       "      <td>0.137247</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>0.144095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.96176</td>\n",
       "      <td>0.133546</td>\n",
       "      <td>0.9606</td>\n",
       "      <td>0.143283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.96284</td>\n",
       "      <td>0.130197</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.138686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.96412</td>\n",
       "      <td>0.127086</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.138593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.96470</td>\n",
       "      <td>0.123879</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>0.133945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.96572</td>\n",
       "      <td>0.120858</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.133092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.96666</td>\n",
       "      <td>0.118160</td>\n",
       "      <td>0.9637</td>\n",
       "      <td>0.130692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.96724</td>\n",
       "      <td>0.115354</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.128359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.96792</td>\n",
       "      <td>0.112720</td>\n",
       "      <td>0.9664</td>\n",
       "      <td>0.126878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.96920</td>\n",
       "      <td>0.110013</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.124704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.96998</td>\n",
       "      <td>0.107606</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.124013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.97064</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.122089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.97148</td>\n",
       "      <td>0.103039</td>\n",
       "      <td>0.9677</td>\n",
       "      <td>0.119438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.97156</td>\n",
       "      <td>0.100882</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.118852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.97228</td>\n",
       "      <td>0.098691</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.118166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.97350</td>\n",
       "      <td>0.096612</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.117127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.97388</td>\n",
       "      <td>0.094559</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.114386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.97398</td>\n",
       "      <td>0.092688</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>0.113317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.97474</td>\n",
       "      <td>0.090724</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.113054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.97554</td>\n",
       "      <td>0.088993</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.111449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.97594</td>\n",
       "      <td>0.087305</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.110227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.97674</td>\n",
       "      <td>0.085489</td>\n",
       "      <td>0.9709</td>\n",
       "      <td>0.109222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.97666</td>\n",
       "      <td>0.083919</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.110216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.97742</td>\n",
       "      <td>0.082203</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.107360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy      loss  val_accuracy  val_loss\n",
       "0    0.72298  1.209267        0.8680  0.579133\n",
       "1    0.87376  0.501137        0.9002  0.387602\n",
       "2    0.89406  0.390832        0.9113  0.331051\n",
       "3    0.90482  0.344322        0.9171  0.303045\n",
       "4    0.91168  0.315959        0.9215  0.282547\n",
       "5    0.91644  0.294830        0.9264  0.264752\n",
       "6    0.92206  0.277891        0.9301  0.253701\n",
       "7    0.92552  0.263938        0.9337  0.241765\n",
       "8    0.92824  0.251351        0.9340  0.234733\n",
       "9    0.93192  0.240120        0.9390  0.223857\n",
       "10   0.93488  0.230177        0.9407  0.215621\n",
       "11   0.93806  0.220898        0.9426  0.210354\n",
       "12   0.93954  0.212557        0.9446  0.202781\n",
       "13   0.94164  0.204748        0.9469  0.195745\n",
       "14   0.94428  0.197460        0.9490  0.190612\n",
       "15   0.94580  0.190568        0.9490  0.185398\n",
       "16   0.94744  0.184370        0.9514  0.179169\n",
       "17   0.94890  0.178254        0.9540  0.175808\n",
       "18   0.95036  0.172728        0.9537  0.171374\n",
       "19   0.95216  0.167181        0.9546  0.166806\n",
       "20   0.95332  0.162292        0.9554  0.163837\n",
       "21   0.95494  0.157700        0.9572  0.158569\n",
       "22   0.95618  0.153009        0.9582  0.155582\n",
       "23   0.95742  0.148780        0.9592  0.153431\n",
       "24   0.95838  0.144796        0.9594  0.149390\n",
       "25   0.95978  0.140951        0.9604  0.147342\n",
       "26   0.96094  0.137247        0.9614  0.144095\n",
       "27   0.96176  0.133546        0.9606  0.143283\n",
       "28   0.96284  0.130197        0.9630  0.138686\n",
       "29   0.96412  0.127086        0.9632  0.138593\n",
       "30   0.96470  0.123879        0.9648  0.133945\n",
       "31   0.96572  0.120858        0.9640  0.133092\n",
       "32   0.96666  0.118160        0.9637  0.130692\n",
       "33   0.96724  0.115354        0.9653  0.128359\n",
       "34   0.96792  0.112720        0.9664  0.126878\n",
       "35   0.96920  0.110013        0.9668  0.124704\n",
       "36   0.96998  0.107606        0.9668  0.124013\n",
       "37   0.97064  0.105300        0.9673  0.122089\n",
       "38   0.97148  0.103039        0.9677  0.119438\n",
       "39   0.97156  0.100882        0.9681  0.118852\n",
       "40   0.97228  0.098691        0.9676  0.118166\n",
       "41   0.97350  0.096612        0.9680  0.117127\n",
       "42   0.97388  0.094559        0.9693  0.114386\n",
       "43   0.97398  0.092688        0.9692  0.113317\n",
       "44   0.97474  0.090724        0.9699  0.113054\n",
       "45   0.97554  0.088993        0.9699  0.111449\n",
       "46   0.97594  0.087305        0.9704  0.110227\n",
       "47   0.97674  0.085489        0.9709  0.109222\n",
       "48   0.97666  0.083919        0.9701  0.110216\n",
       "49   0.97742  0.082203        0.9700  0.107360"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.1043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09116246551275253, 0.9724000096321106]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zl/x4wcpc6n7p75fkkmssl2_0vh0000gn/T/ipykernel_26144/1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.003, 0.   , 0.   , 0.   , 0.997, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zl/x4wcpc6n7p75fkkmssl2_0vh0000gn/T/ipykernel_26144/1084033691.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.any(np.isnan(X_train)))\n",
    "print(np.any(np.isnan(X_valid)))\n",
    "print(np.any(np.isnan(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - loss: 1.9511 - val_loss: 0.5457\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - loss: 0.5583 - val_loss: 0.4760\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - loss: 0.5168 - val_loss: 0.4524\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 49ms/step - loss: 0.5171 - val_loss: 0.4398\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - loss: 0.4967 - val_loss: 0.4266\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 70ms/step - loss: 0.4653 - val_loss: 0.4186\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - loss: 0.4578 - val_loss: 0.4108\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 44ms/step - loss: 0.4616 - val_loss: 0.4061\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 43ms/step - loss: 0.4427 - val_loss: 0.4037\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - loss: 0.4067 - val_loss: 0.3979\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 44ms/step - loss: 0.4185 - val_loss: 0.3926\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 44ms/step - loss: 0.4186 - val_loss: 0.3891\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - loss: 0.4128 - val_loss: 0.3887\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 63ms/step - loss: 0.4034 - val_loss: 0.3815\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - loss: 0.3966 - val_loss: 0.3825\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - loss: 0.3971 - val_loss: 0.3752\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 72ms/step - loss: 0.3988 - val_loss: 0.3767\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 40ms/step - loss: 0.3995 - val_loss: 0.3713\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 40ms/step - loss: 0.3928 - val_loss: 0.3681\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 46ms/step - loss: 0.3917 - val_loss: 0.3681\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.SGD(clipnorm=1)\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = optimizer) # con optimizer = \"sgd\" aparece la explosión del gradiente y nan's \n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">303</span> (1.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m303\u001b[0m (1.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.3815\n",
      "0.3855123221874237\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.5858588],\n",
       "       [1.477194 ],\n",
       "       [1.1415502],\n",
       "       [1.1022723],\n",
       "       [2.328269 ]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El optimizador que se usó para compilar el modelo contiene estado interno (por ejemplo, acumuladores de gradiente) que ya no coincide con las variables actuales del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una nueva instancia del optimizador\n",
    "new_optimizer = keras.optimizers.SGD(clipnorm=1, learning_rate=0.01)\n",
    "\n",
    "# Recompilar el modelo con el nuevo optimizador\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=new_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3825"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 47ms/step - loss: 0.3825\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3758"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 78ms/step - loss: 0.3758\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - loss: 0.3835\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3773"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 62ms/step - loss: 0.3773\n",
      "Epoch 5/20\n",
      "\u001b[1m362/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3895"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - loss: 0.3894\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 60ms/step - loss: 0.3710\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 65ms/step - loss: 0.3832\n",
      "Epoch 8/20\n",
      "\u001b[1m362/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.3626\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - loss: 0.3670\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3630"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - loss: 0.3630\n",
      "Epoch 11/20\n",
      "\u001b[1m362/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.3525"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 103ms/step - loss: 0.3526\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3604"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 55ms/step - loss: 0.3604\n",
      "Epoch 13/20\n",
      "\u001b[1m362/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 40ms/step - loss: 0.3707\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3638"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - loss: 0.3638\n",
      "Epoch 15/20\n",
      "\u001b[1m362/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3615"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 43ms/step - loss: 0.3614\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3622"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - loss: 0.3621\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3581"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 38ms/step - loss: 0.3581\n",
      "Epoch 18/20\n",
      "\u001b[1m362/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 37ms/step - loss: 0.3438\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3604"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - loss: 0.3603\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - loss: 0.3510\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=20,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3366 - val_loss: 0.3556\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3356 - val_loss: 0.3625\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3352 - val_loss: 0.3562\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3349 - val_loss: 0.3583\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3341 - val_loss: 0.3520\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3328 - val_loss: 0.3556\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.3512\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.3579\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3324 - val_loss: 0.3559\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3309 - val_loss: 0.3505\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3303 - val_loss: 0.3482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3288 - val_loss: 0.3528\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3286 - val_loss: 0.3525\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3284 - val_loss: 0.3479\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3276 - val_loss: 0.3523\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3276 - val_loss: 0.3486\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3271 - val_loss: 0.3461\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3262 - val_loss: 0.3519\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3262 - val_loss: 0.3521\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3256 - val_loss: 0.3547\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=20,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
